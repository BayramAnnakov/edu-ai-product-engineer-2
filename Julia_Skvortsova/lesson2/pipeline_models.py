"""Data models for the review analysis pipeline"""
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional, Union


class ReviewData(BaseModel):
    """Raw review data from CSV"""
    id: int
    source_id: int
    published_at: datetime
    rating: int
    sentiment: int
    categories: list[str]
    content: str


class ReviewSummary(BaseModel):
    """Summary of all reviews"""
    total_reviews: int
    average_rating: float
    sentiment_distribution: dict[str, int]
    executive_summary: str
    top_complaints: list[dict[str, str | float]]
    positive_feedback: list[dict[str, str | float]]
    technical_issues: list[str]
    improvement_suggestions: list[str]
    confidence_score: float = Field(ge=0, le=100)
    limitations: list[str]


class FeatureRequest(BaseModel):
    """Extracted feature request"""
    id: str
    description: str
    category: str
    frequency: int
    example_quotes: list[str]
    sentiment: float = Field(ge=-1, le=1)


class FeatureExtractionOutput(BaseModel):
    """Structured output for feature extraction agent"""
    features: list[FeatureRequest]


class ExtractedPersona(BaseModel):
    """Persona extracted from reviews"""
    id: str
    name: str
    background: str
    pain_points: list[str]
    needs: list[str]
    review_quotes: list[str]
    frequency: float = Field(ge=0, le=1, description="Percentage of reviews matching this persona")


class PersonaExtractionOutput(BaseModel):
    """Structured output for persona extraction agent"""
    personas: list[ExtractedPersona]


class PersonaMatch(BaseModel):
    """Match between extracted and existing personas"""
    extracted_persona_id: str
    existing_persona_id: Optional[str]
    match_score: float = Field(ge=0, le=1)
    rationale: str


class PersonaMatchingOutput(BaseModel):
    """Structured output for persona matching agent"""
    matches: list[PersonaMatch]


class RICEScore(BaseModel):
    """RICE prioritization score"""
    feature_id: str
    feature_description: str
    reach_percent: float = Field(ge=0, le=100)
    impact: str = Field(pattern="^(High|Medium|Low)$")
    confidence: str = Field(pattern="^(High|Medium|Low)$")
    effort_weeks: float = Field(gt=0)
    rice_score: float = 0.0
    
    def calculate_score(self) -> float:
        """Calculate RICE score"""
        if self.effort_weeks == 0:
            self.rice_score = 0.0
            return 0.0  # Avoid division by zero

        impact_map = {"High": 3, "Medium": 2, "Low": 1}
        confidence_map = {"High": 1.0, "Medium": 0.8, "Low": 0.5}
        
        impact_val = impact_map[self.impact]
        confidence_val = confidence_map[self.confidence]
        
        self.rice_score = (self.reach_percent * impact_val * confidence_val) / self.effort_weeks
        return self.rice_score


class RICEScoringOutput(BaseModel):
    """Structured output for RICE scoring agent"""
    scores: list[RICEScore]


class ProductHypothesis(BaseModel):
    """Hypothesis to test about the product"""
    id: str
    description: str
    assumption: str


class ProductConcept(BaseModel):
    """Detailed product concept generated by LLM"""
    name: str
    tagline: str
    description: str
    target_market: str
    key_value_propositions: list[str]
    core_features: list[str]
    hypotheses_to_test: list[ProductHypothesis]
    success_metrics: list[str]
    
    @property
    def one_sentence_description(self) -> str:
        """Generate short description for market research"""
        return self.tagline


class ProductConceptOutput(BaseModel):
    """Structured output for product concept agent"""
    product_concept: ProductConcept


class ProductIdea(BaseModel):
    """Legacy product idea model - keeping for compatibility"""
    name: str
    description: str
    one_sentence_description: str
    target_personas: list[str]
    key_features: list[str]
    hypotheses: list[dict[str, str]]
    
    @classmethod
    def from_concept(cls, concept: ProductConcept, personas: list[str]) -> "ProductIdea":
        """Create ProductIdea from ProductConcept for compatibility"""
        return cls(
            name=concept.name,
            description=concept.description,
            one_sentence_description=concept.one_sentence_description,
            target_personas=personas,
            key_features=concept.core_features,
            hypotheses=[
                {"id": h.id, "description": h.description}
                for h in concept.hypotheses_to_test
            ]
        )


class PipelineArtifacts(BaseModel):
    """All artifacts from pipeline run"""
    timestamp: datetime
    summary: ReviewSummary
    features: list[FeatureRequest]
    personas: list[ExtractedPersona]
    persona_matches: list[PersonaMatch]
    priorities: list[RICEScore]
    product_concept: ProductConcept
    top_idea: ProductIdea
    market_research_prompt: str
    board_config_path: str
    final_report_path: Optional[str] = None


class PipelineConfig(BaseModel):
    """Configuration for pipeline execution"""
    reviews_file: str = "data/reviews.csv"
    personas_file: str = "docs/personas.yml"
    output_language: str = "English"
    artifacts_dir: str = "artifacts"
    prompts_dir: str = "prompts"
    
    # Model settings
    reasoning_model: str = "gpt-4.1"
    categorization_model: str = "gpt-4.1-nano"
    
    # Feature extraction settings
    min_feature_frequency: int = 2
    max_features_to_extract: int = 10
    
    # RICE scoring settings
    default_effort_weeks: float = 2.0
    
    # Virtual board settings
    num_personas_for_board: int = 4
    max_hypotheses: int = 3


class DivergeQuestion(BaseModel):
    """A structured diverge question with hypothesis coverage"""
    text: str
    covers: list[str]
    rationale: str


class ResearchQuestions(BaseModel):
    """Research questions for virtual board phases"""
    warmup: list[str]
    diverge: list[DivergeQuestion]
    converge: list[str]
    closure: list[str]


class ResearchQuestionsOutput(BaseModel):
    """Structured output for research questions agent"""
    hypotheses: Optional[list[ProductHypothesis]] = []
    research_questions: ResearchQuestions