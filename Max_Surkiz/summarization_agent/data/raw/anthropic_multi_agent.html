<!DOCTYPE html><html lang="en" class="__variable_5e9598 __variable_403256 __variable_57fc85 __variable_34e0db __variable_862ba3"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/4e8887750eb14755-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/5dd0369324c6e67e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/844eb89fa4effbb2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/afcde17c90040887-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/c1cf232a330ed002-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/cfe503504e29ad5d-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/d7440d3c533a1aec-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/db2277a4dc542e54-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/9bf880a802bdb80b.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/c590bd4b041dc657.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/2e0d62ccdb367d80.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/1607ca09b8e6c25e.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/0e2a6e211da5747f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/00a642b57d96adff.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/52994232fd15d79f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/18b72fe33e784864.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/579a43ce119caf67.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx" href="/_next/static/chunks/webpack-d8dc115719352f34.js"/><script src="/_next/static/chunks/fd9d1056-0b3d1e0b010ff572.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/7023-f8015d96972cd1bb.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/main-app-55bbd77d79f9187f.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/d8e9270f-d57a4faa183a21b3.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/cc3e2e0e-9a8a205950288c5c.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/d8f92815-58bfe84c979b4d69.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/20e9ecfc-2a45032f86ca4c33.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/ccd63cfe-be58d908b1d80a17.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/3204862b-324c96543028037a.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/8ace8c09-2ef1471301516487.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/13b76428-b914bed72c3f2a72.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/c15bf2b0-805db01d15bd4563.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/8616-254847c413581317.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/6553-ebf326f74c5292d7.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/9450-09246fba0b06068f.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/1204-b63115b25250d7bb.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/9582-0f16bbc87808f931.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/7337-3a2e22eeed3410c4.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/2091-72ee32de691ba886.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/5749-fdb2b822e2252a4a.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/7510-98b0678559316e26.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/6787-f554d19c61e08a1b.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/4062-742ddec75f52b5f2.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/app/(site)/%5B%5B...slug%5D%5D/page-097dda26631bad1e.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/app/(site)/layout-3309f2b8a131fb7a.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/app/(site)/engineering/%5Bslug%5D/page-e9f67ae7d0165724.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><script src="/_next/static/chunks/app/(site)/not-found-4ae41f9e6f9717e3.js" async="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script><meta name="theme-color" content="#141413"/><title>How we built our multi-agent research system \ Anthropic</title><meta name="description" content="On the the engineering challenges and lessons learned from building Claude&#x27;s Research system"/><meta name="msapplication-TileColor" content="141413"/><meta name="msapplication-config" content="/browserconfig.xml"/><meta property="og:title" content="How we built our multi-agent research system"/><meta property="og:description" content="On the the engineering challenges and lessons learned from building Claude&#x27;s Research system"/><meta property="og:image" content="https://cdn.sanity.io/images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png"/><meta property="og:image:alt" content="Anthropic logo"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@AnthropicAI"/><meta name="twitter:creator" content="@AnthropicAI"/><meta name="twitter:title" content="How we built our multi-agent research system"/><meta name="twitter:description" content="On the the engineering challenges and lessons learned from building Claude&#x27;s Research system"/><meta name="twitter:image" content="https://cdn.sanity.io/images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png"/><meta name="twitter:image:alt" content="Anthropic logo"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/images/icons/favicon-32x32.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180"/><link rel="mask-icon" href="/images/icons/safari-pinned-tab.svg" color="141413"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule="" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx"></script></head><body><header class="SiteHeader_header__JZwqp" data-theme="light"><div class="SiteHeader_skipLinks__FBJM_"><a href="#main-content" class="SiteHeader_skipLink__5cD_c">Skip to main content</a><a href="#footer" class="SiteHeader_skipLink__5cD_c">Skip to footer</a></div><div class="page-wrapper SiteHeader_root__4Xd52"><a href="/" aria-label="Home"><div class="SiteHeader_logoDesktop__QF_jY"><div class="LogoWordmark_logo-lottie__HlhID"></div></div><svg class="Icon_icon__UdTNj SiteHeader_logoMobile__4zcw_" width="32" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="#000000"></path></svg></a><div class="SiteHeader_contentWrapper__UUrBN"><nav class="SiteHeader_nav__fFHf4"><ul class="SiteHeader_navList__TC1Q_"><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Claude"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-Claude">Claude</button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="API"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-API">API</button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Solutions"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-Solutions">Solutions</button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Research"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-Research">Research</button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Commitments"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-Commitments">Commitments</button></li><li class="detail-m SiteHeader_navItem__iLoj9" data-category="Learn"><button class="SiteHeader_navText__fhzDU" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-drawer-Learn">Learn</button></li><a href="/news" class="detail-m SiteHeader_navItem__iLoj9" referrerPolicy="no-referrer-when-downgrade"><span class="SiteHeader_navText__fhzDU">News</span></a></ul></nav><a href="https://claude.ai/" class="ButtonCta_button__miruF detail-m SiteHeader_navCta__EnESr" rel="noopener" target="_blank" referrerPolicy="no-referrer-when-downgrade" aria-label="Try Claude"><span>Try Claude</span></a><button class="SiteHeader_mobileIcon__OK1HE" aria-label="Navigation menu"><svg class="Icon_icon__UdTNj" width="24" height="24" viewBox="0 0 40 40"><path d="M5.418 25.375v-2.083h29.166v2.083H5.418Zm0-8.667v-2.083h29.166v2.083H5.418Z" fill="#141413"></path></svg></button></div></div></header><main id="main-content" class=""><section class="page-wrapper HeroEngineering_hero__MmK87" aria-label="Engineering Article Hero"><a class="detail-m bold HeroEngineering_hubLink__tSdcv" href="/engineering">Engineering at Anthropic</a><div class="HeroEngineering_content__3awDN"><div class="HeroEngineering_header__fl24a"><div class="HeroEngineering_heroImage__7BZXh"><img alt="" loading="lazy" width="1000" height="1000" decoding="async" data-nimg="1" style="color:transparent" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000.svg"/></div><h1 class="display-sans-xl bold">How we built our multi-agent research system</h1></div><div class="HeroEngineering_metadata__6bMUi"><p class="detail-m HeroEngineering_date__OnXQl">Published <!-- -->Jun 13, 2025</p><p class="detail-xl HeroEngineering_summary__prg8C">Our Research feature uses multiple Claude agents to explore complex topics more effectively. We share the engineering challenges and the lessons we learned from building this system.</p></div></div></section><div class="page-wrapper"><article><div class=""><div class="Body_body__XEXq7"><p class="Body_reading-column__t7kGM paragraph-m post-text">Claude now has <a href="https://www.anthropic.com/news/research">Research capabilities</a> that allow it to search across the web, Google Workspace, and any integrations to accomplish complex tasks.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">The journey of this multi-agent system from prototype to production taught us critical lessons about system architecture, tool design, and prompt engineering. A multi-agent system consists of multiple agents (LLMs autonomously using tools in a loop) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously. Systems with multiple agents introduce new challenges in agent coordination, evaluation, and reliability. </p><p class="Body_reading-column__t7kGM paragraph-m post-text">This post breaks down the principles that worked for us—we hope you&#x27;ll find them useful to apply when building your own multi-agent systems.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="benefits-of-a-multi-agent-system">Benefits of a multi-agent system</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Research work involves open-ended problems where it’s very difficult to predict the required steps in advance. You can’t hardcode a fixed path for exploring complex topics, as the process is inherently dynamic and path-dependent. When people conduct research, they tend to continuously update their approach based on discoveries, following leads that emerge during investigation.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">This unpredictability makes AI agents particularly well-suited for research tasks. Research demands the flexibility to pivot or explore tangential connections as the investigation unfolds. The model must operate autonomously for many turns, making decisions about which directions to pursue based on intermediate findings. A linear, one-shot pipeline cannot handle these tasks.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">The essence of search is compression: distilling insights from a vast corpus. Subagents facilitate compression by operating in parallel with their own context windows, exploring different aspects of the question simultaneously before condensing the most important tokens for the lead research agent. Each subagent also provides separation of concerns—distinct tools, prompts, and exploration trajectories—which reduces path dependency and enables thorough, independent investigations.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Once intelligence reaches a threshold, multi-agent systems become a vital way to scale performance. For instance, although individual humans have become more intelligent in the last 100,000 years, human societies have become <em>exponentially</em> more capable in the information age because of our <em>collective</em> intelligence and ability to coordinate. Even generally-intelligent agents face limits when operating as individuals; groups of agents can accomplish far more.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Our internal evaluations show that multi-agent research systems excel especially for breadth-first queries that involve pursuing multiple independent directions simultaneously. We found that a multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on our internal research eval. For example, when asked to identify all the board members of the companies in the Information Technology S&amp;P 500, the multi-agent system found the correct answers by decomposing this into tasks for subagents, while the single agent system failed to find the answer with slow, sequential searches.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Multi-agent systems work mainly because they help spend enough tokens to solve the problem. In our analysis, three factors explained 95% of the performance variance in the <a href="https://openai.com/index/browsecomp/">BrowseComp</a> evaluation (which tests the ability of browsing agents to locate hard-to-find information). We found that token usage by itself explains 80% of the variance, with the number of tool calls and the model choice as the two other explanatory factors. This finding validates our architecture that distributes work across agents with separate context windows to add more capacity for parallel reasoning. The latest Claude models act as large efficiency multipliers on token use, as upgrading to Claude Sonnet 4 is a larger performance gain than doubling the token budget on Claude Sonnet 3.7. Multi-agent architectures effectively scale token usage for tasks that exceed the limits of single agents.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">There is a downside: in practice, these architectures burn through tokens fast. In our data, agents typically use about 4× more tokens than chat interactions, and multi-agent systems use about 15× more tokens than chats. For economic viability, multi-agent systems require tasks where the value of the task is high enough to pay for the increased performance. Further, some domains that require all agents to share the same context or involve many dependencies between agents are not a good fit for multi-agent systems today. For instance, most coding tasks involve fewer truly parallelizable tasks than research, and LLM agents are not yet great at coordinating and delegating to other agents in real time. We’ve found that multi-agent systems excel at valuable tasks that involve heavy parallelization, information that exceeds single context windows, and interfacing with numerous complex tools.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="architecture-overview-for-research">Architecture overview for Research</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Our Research system uses a multi-agent architecture with an orchestrator-worker pattern, where a lead agent coordinates the process while delegating to specialized subagents that operate in parallel.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="4584" height="2579" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">The multi-agent architecture in action: user queries flow through a lead agent that creates specialized subagents to search for different aspects in parallel.</figcaption></figure></div><p class="Body_reading-column__t7kGM paragraph-m post-text">When a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. As shown in the diagram above, the subagents act as intelligent filters by iteratively using search tools to gather information, in this case on AI agent companies in 2025, and then returning a list of companies to the lead agent so it can compile a final answer.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Traditional approaches using Retrieval Augmented Generation (RAG) use static retrieval. That is, they fetch some set of chunks that are most similar to an input query and use these chunks to generate a response. In contrast, our architecture uses a multi-step search that dynamically finds relevant information, adapts to new findings, and analyzes results to formulate high-quality answers.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_ ImageWithCaption_narrow__qFYCv"><img loading="lazy" width="4584" height="4584" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">Process diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any number) with specific research tasks. Each Subagent independently performs web searches, evaluates tool results using <a href="https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking">interleaved thinking</a>, and returns findings to the LeadResearcher. The LeadResearcher synthesizes these results and decides whether more research is needed—if so, it can create additional subagents or refine its strategy. Once sufficient information is gathered, the system exits the research loop and passes all findings to a CitationAgent, which processes the documents and research report to identify specific locations for citations. This ensures all claims are properly attributed to their sources. The final research results, complete with citations, are then returned to the user.</figcaption></figure></div><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="prompt-engineering-and-evaluations-for-research-agents">Prompt engineering and evaluations for research agents</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Multi-agent systems have key differences from single-agent systems, including a rapid growth in coordination complexity. Early agents made errors like spawning 50 subagents for simple queries, scouring the web endlessly for nonexistent sources, and distracting each other with excessive updates. Since each agent is steered by a prompt, prompt engineering was our primary lever for improving these behaviors. Below are some principles we learned for prompting agents:</p><ol class="Body_reading-column__t7kGM paragraph-m post-text"><li><strong>Think like your agents. </strong>To iterate on prompts, you must understand their effects. To help us do this, we built simulations using our <a href="https://console.anthropic.com/">Console</a> with the exact prompts and tools from our system, then watched agents work step-by-step. This immediately revealed failure modes: agents continuing when they already had sufficient results, using overly verbose search queries, or selecting incorrect tools. Effective prompting relies on developing an accurate mental model of the agent, which can make the most impactful changes obvious.</li><li><strong>Teach the orchestrator how to delegate.</strong> In our system, the lead agent decomposes queries into subtasks and describes them to subagents. Each subagent needs an objective, an output format, guidance on the tools and sources to use, and clear task boundaries. Without detailed task descriptions, agents duplicate work, leave gaps, or fail to find necessary information. We started by allowing the lead agent to give simple, short instructions like &#x27;research the semiconductor shortage,&#x27; but found these instructions often were vague enough that subagents misinterpreted the task or performed the exact same searches as other agents. For instance, one subagent explored the 2021 automotive chip crisis while 2 others duplicated work investigating current 2025 supply chains, without an effective division of labor.</li><li><strong>Scale effort to query complexity. </strong>Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries, which was a common failure mode in our early versions.</li><li><strong>Tool design and selection are critical. </strong>Agent-tool interfaces are as critical as human-computer interfaces. Using the right tool is efficient—often, it’s strictly necessary. For instance, an agent searching the web for context that only exists in Slack is doomed from the start. With <a href="https://modelcontextprotocol.io/introduction">MCP servers</a> that give the model access to external tools, this problem compounds, as agents encounter unseen tools with descriptions of wildly varying quality. We gave our agents explicit heuristics: for example, examine all available tools first, match tool usage to user intent, search the web for broad external exploration, or prefer specialized tools over generic ones. Bad tool descriptions can send agents down completely wrong paths, so each tool needs a distinct purpose and a clear description.</li><li><strong>Let agents improve themselves</strong>. We found that the Claude 4 models can be excellent prompt engineers. When given a prompt and a failure mode, they are able to diagnose why the agent is failing and suggest improvements. We even created a tool-testing agent—when given a flawed MCP tool, it attempts to use the tool and then rewrites the tool description to avoid failures. By testing the tool dozens of times, this agent found key nuances and bugs. This process for improving tool ergonomics resulted in a 40% decrease in task completion time for future agents using the new description, because they were able to avoid most mistakes.</li><li><strong>Start wide, then narrow down.</strong> Search strategy should mirror expert human research: explore the landscape before drilling into specifics. Agents often default to overly long, specific queries that return few results. We counteracted this tendency by prompting agents to start with short, broad queries, evaluate what’s available, then progressively narrow focus.</li><li><strong>Guide the thinking process.</strong> <a href="https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking">Extended thinking mode</a>, which leads Claude to output additional tokens in a visible thinking process, can serve as a controllable scratchpad. The lead agent uses thinking to plan its approach, assessing which tools fit the task, determining query complexity and subagent count, and defining each subagent’s role. Our testing showed that extended thinking improved instruction-following, reasoning, and efficiency. Subagents also plan, then use <a href="https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking">interleaved thinking</a> after tool results to evaluate quality, identify gaps, and refine their next query. This makes subagents more effective in adapting to any task.</li><li><strong>Parallel tool calling transforms speed and performance.</strong> Complex research tasks naturally involve exploring many sources. Our early agents executed sequential searches, which was painfully slow. For speed, we introduced two kinds of parallelization: (1) the lead agent spins up 3-5 subagents in parallel rather than serially; (2) the subagents use 3+ tools in parallel. These changes cut research time by up to 90% for complex queries, allowing Research to do more work in minutes instead of hours while covering more information than other systems.</li></ol><p class="Body_reading-column__t7kGM paragraph-m post-text">Our prompting strategy focuses on instilling good heuristics rather than rigid rules. We studied how skilled humans approach research tasks and encoded these strategies in our prompts—strategies like decomposing difficult questions into smaller tasks, carefully evaluating the quality of sources, adjusting search approaches based on new information, and recognizing when to focus on depth (investigating one topic in detail) vs. breadth (exploring many topics in parallel). We also proactively mitigated unintended side effects by setting explicit guardrails to prevent the agents from spiraling out of control. Finally, we focused on a fast iteration loop with observability and test cases.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="effective-evaluation-of-agents">Effective evaluation of agents</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Good evaluations are essential for building reliable AI applications, and agents are no different. However, evaluating multi-agent systems presents unique challenges. Traditional evaluations often assume that the AI follows the same steps each time: given input X, the system should follow path Y to produce output Z. But multi-agent systems don&#x27;t work this way. Even with identical starting points, agents might take completely different valid paths to reach their goal. One agent might search three sources while another searches ten, or they might use different tools to find the same answer. Because we don’t always know what the right steps are, we usually can&#x27;t just check if agents followed the “correct” steps we prescribed in advance. Instead, we need flexible evaluation methods that judge whether agents achieved the right outcomes while also following a reasonable process.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Start evaluating immediately with small samples</strong>. In early agent development, changes tend to have dramatic impacts because there is abundant low-hanging fruit. A prompt tweak might boost success rates from 30% to 80%. With effect sizes this large, you can spot changes with just a few test cases. We started with a set of about 20 queries representing real usage patterns. Testing these queries often allowed us to clearly see the impact of changes. We often hear that AI developer teams delay creating evals because they believe that only large evals with hundreds of test cases are useful. However, it’s best to start with small-scale testing right away with a few examples, rather than delaying until you can build more thorough evals.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>LLM-as-judge evaluation scales when done well.</strong> Research outputs are difficult to evaluate programmatically, since they are free-form text and rarely have a single correct answer. LLMs are a natural fit for grading outputs. We used an LLM judge that evaluated each output against criteria in a rubric: factual accuracy (do claims match sources?), citation accuracy (do the cited sources match the claims?), completeness (are all requested aspects covered?), source quality (did it use primary sources over lower-quality secondary sources?), and tool efficiency (did it use the right tools a reasonable number of times?). We experimented with multiple judges to evaluate each component, but found that a single LLM call with a single prompt outputting scores from 0.0-1.0 and a pass-fail grade was the most consistent and aligned with human judgements. This method was especially effective when the eval test cases <em>did</em> have a clear answer, and we could use the LLM judge to simply check if the answer was correct (i.e. did it accurately list the pharma companies with the top 3 largest R&amp;D budgets?). Using an LLM as a judge allowed us to scalably evaluate hundreds of outputs.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Human evaluation catches what automation misses.</strong> People testing agents find edge cases that evals miss. These include hallucinated answers on unusual queries, system failures, or subtle source selection biases. In our case, human testers noticed that our early agents consistently chose SEO-optimized content farms over authoritative but less highly-ranked sources like academic PDFs or personal blogs. Adding source quality heuristics to our prompts helped resolve this issue. Even in a world of automated evaluations, manual testing remains essential.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Multi-agent systems have emergent behaviors, which arise without specific programming. For instance, small changes to the lead agent can unpredictably change how subagents behave. Success requires understanding interaction patterns, not just individual agent behavior. Therefore, the best prompts for these agents are not just strict instructions, but frameworks for collaboration that define the division of labor, problem-solving approaches, and effort budgets. Getting this right relies on careful prompting and tool design, solid heuristics, observability, and tight feedback loops.<strong> </strong>See the <a href="https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts">open-source prompts in our Cookbook</a> for example prompts from our system.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="production-reliability-and-engineering-challenges">Production reliability and engineering challenges</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">In traditional software, a bug might break a feature, degrade performance, or cause outages. In agentic systems, minor changes cascade into large behavioral changes, which makes it remarkably difficult to write code for complex agents that must maintain state in a long-running process.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Agents are stateful and errors compound. </strong>Agents can run for long periods of time, maintaining state across many tool calls. This means we need to durably execute code and handle errors along the way. Without effective mitigations, minor system failures can be catastrophic for agents. When errors occur, we can&#x27;t just restart from the beginning: restarts are expensive and frustrating for users. Instead, we built systems that can resume from where the agent was when the errors occurred. We also use the model’s intelligence to handle issues gracefully: for instance, letting the agent know when a tool is failing and letting it adapt works surprisingly well. We combine the adaptability of AI agents built on Claude with deterministic safeguards like retry logic and regular checkpoints.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Debugging benefits from new approaches. </strong>Agents make dynamic decisions and are non-deterministic between runs, even with identical prompts. This makes debugging harder. For instance, users would report agents “not finding obvious information,” but we couldn&#x27;t see why. Were the agents using bad search queries? Choosing poor sources? Hitting tool failures? Adding full production tracing let us diagnose why agents failed and fix issues systematically. Beyond standard observability, we monitor agent decision patterns and interaction structures—all without monitoring the contents of individual conversations, to maintain user privacy. This high-level observability helped us diagnose root causes, discover unexpected behaviors, and fix common failures.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Deployment needs careful coordination.</strong> Agent systems are highly stateful webs of prompts, tools, and execution logic that run almost continuously. This means that whenever we deploy updates, agents might be anywhere in their process. We therefore need to prevent our well-meaning code changes from breaking existing agents. We can’t update every agent to the new version at the same time. Instead, we use <a href="https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/">rainbow deployments</a> to avoid disrupting running agents, by gradually shifting traffic from old to new versions while keeping both running simultaneously.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Synchronous execution creates bottlenecks.</strong> Currently, our lead agents execute subagents synchronously, waiting for each set of subagents to complete before proceeding. This simplifies coordination, but creates bottlenecks in the information flow between agents. For instance, the lead agent can’t steer subagents, subagents can’t coordinate, and the entire system can be blocked while waiting for a single subagent to finish searching. Asynchronous execution would enable additional parallelism: agents working concurrently and creating new subagents when needed. But this asynchronicity adds challenges in result coordination, state consistency, and error propagation across the subagents. As models can handle longer and more complex research tasks, we expect the performance gains will justify the complexity.</p><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="conclusion">Conclusion</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">When building AI agents, the last mile often becomes most of the journey. Codebases that work on developer machines require significant engineering to become reliable production systems. The compound nature of errors in agentic systems means that minor issues for traditional software can derail agents entirely. One step failing can cause agents to explore entirely different trajectories, leading to unpredictable outcomes. For all the reasons described in this post, the gap between prototype and production is often wider than anticipated.</p><p class="Body_reading-column__t7kGM paragraph-m post-text">Despite these challenges, multi-agent systems have proven valuable for open-ended research tasks. Users have said that Claude helped them find business opportunities they hadn’t considered, navigate complex healthcare options, resolve thorny technical bugs, and save up to days of work by uncovering research connections they wouldn&#x27;t have found alone. Multi-agent research systems can operate reliably at scale with careful engineering, comprehensive testing, detail-oriented prompt and tool design, robust operational practices, and tight collaboration between research, product, and engineering teams who have a strong understanding of current agent capabilities. We&#x27;re already seeing these systems transform how people solve complex problems.</p><div class="Body_media-column__xPzhg"><figure class="ImageWithCaption_e-imageWithCaption__8C2mY ImageWithCaption_inline-image__B15e_"><img loading="lazy" width="2654" height="2148" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png&amp;w=3840&amp;q=75"/><figcaption class="text-caption">A <a href="https://www.anthropic.com/research/clio">Clio</a> embedding plot showing the most common ways people are using the Research feature today. The top use case categories are developing software systems across specialized domains (10%), develop and optimize professional and technical content (8%), develop business growth and revenue generation strategies (8%), assist with academic research and educational material development (7%), and research and verify information about people, places, or organizations (5%).</figcaption></figure></div><h3 class="Body_reading-column__t7kGM display-sans-s post-section" id="acknowlegements">Acknowlegements</h3><p class="Body_reading-column__t7kGM paragraph-m post-text">Written by Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, and Daniel Ford. This work reflects the collective efforts of several teams across Anthropic who made the Research feature possible. Special thanks go to the Anthropic apps engineering team, whose dedication brought this complex multi-agent system to production. We&#x27;re also grateful to our early users for their excellent feedback.</p><h2 class="Body_reading-column__t7kGM display-sans-m post-heading" id="appendix">Appendix</h2><p class="Body_reading-column__t7kGM paragraph-m post-text">Below are some additional miscellaneous tips for multi-agent systems.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>End-state evaluation of agents that mutate state over many turns. </strong>Evaluating agents that modify persistent state across multi-turn conversations presents unique challenges. Unlike read-only research tasks, each action can change the environment for subsequent steps, creating dependencies that traditional evaluation methods struggle to handle. We found success focusing on end-state evaluation rather than turn-by-turn analysis. Instead of judging whether the agent followed a specific process, evaluate whether it achieved the correct final state. This approach acknowledges that agents may find alternative paths to the same goal while still ensuring they deliver the intended outcome. For complex workflows, break evaluation into discrete checkpoints where specific state changes should have occurred, rather than attempting to validate every intermediate step.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Long-horizon conversation management. </strong>Production agents often engage in conversations spanning hundreds of turns, requiring careful context management strategies. As conversations extend, standard context windows become insufficient, necessitating intelligent compression and memory mechanisms. We implemented patterns where agents summarize completed work phases and store essential information in external memory before proceeding to new tasks. When context limits approach, agents can spawn fresh subagents with clean contexts while maintaining continuity through careful handoffs. Further, they can retrieve stored context like the research plan from their memory rather than losing previous work when reaching the context limit. This distributed approach prevents context overflow while preserving conversation coherence across extended interactions.</p><p class="Body_reading-column__t7kGM paragraph-m post-text"><strong>Subagent output to a filesystem to minimize the ‘game of telephone.’ </strong>Direct subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. This prevents information loss during multi-stage processing and reduces token overhead from copying large outputs through conversation history. The pattern works particularly well for structured outputs like code, reports, or data visualizations where the subagent&#x27;s specialized prompt produces better results than filtering through a general coordinator.</p></div></div></article></div></main><footer id="footer" class="SiteFooter_root__VoI_L" role="contentinfo" aria-label="Site footer"><div class="page-wrapper SiteFooter_footer__05g7R"><div class="SiteFooter_topWrapper__4QRFq"><a href="/" aria-label="Return to homepage" class="SiteFooter_logo__mwbXk"><svg class="Icon_icon__UdTNj" width="46" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="#faf9f5"></path></svg></a><nav class="SiteFooter_columnsWrapper__L8CP7" aria-label="Footer navigation"><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Product</h3><ul class="SiteFooter_list__jhKng"><li><a href="/claude" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude overview</a></li><li><a href="/claude-code" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude Code</a></li><li><a href="/max" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Max plan</a></li><li><a href="/team" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Team plan</a></li><li><a href="/enterprise" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Enterprise plan</a></li><li><a href="https://claude.ai/download" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank" referrerPolicy="no-referrer-when-downgrade">Download Claude apps</a></li><li><a href="/pricing" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude.ai pricing plans</a></li><li><a href="http://claude.ai/login" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank" referrerPolicy="no-referrer-when-downgrade"> Claude.ai login</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">API Platform</h3><ul class="SiteFooter_list__jhKng"><li><a href="/api" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">API overview</a></li><li><a href="https://docs.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank"> Developer docs</a></li><li><a href="/amazon-bedrock" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude in Amazon Bedrock</a></li><li><a href="/google-cloud-vertex-ai" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude on Google Cloud&#x27;s Vertex AI</a></li><li><a href="/pricing#api" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade"> Pricing</a></li><li><a href="https://console.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Console login</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Research</h3><ul class="SiteFooter_list__jhKng"><li><a href="/research" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Research overview</a></li><li><a href="/economic-index" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Economic Index</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Claude models</h3><ul class="SiteFooter_list__jhKng"><li><a href="/claude/opus" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude Opus 4</a></li><li><a href="/claude/sonnet" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude Sonnet 4</a></li><li><a href="/claude/haiku" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Claude Haiku 3.5</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Commitments</h3><ul class="SiteFooter_list__jhKng"><li><a href="/transparency" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade"> Transparency</a></li><li><a href="/responsible-scaling-policy" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Responsible scaling policy</a></li><li><a href="https://trust.anthropic.com" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Security and compliance</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Solutions</h3><ul class="SiteFooter_list__jhKng"><li><a href="/solutions/agents" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">AI agents</a></li><li><a href="/solutions/coding" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Coding</a></li><li><a href="/solutions/customer-support" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Customer support</a></li><li><a href="/solutions/education" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Education</a></li><li><a href="/solutions/financial-services" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Financial services</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Learn</h3><ul class="SiteFooter_list__jhKng"><li><a href="/learn" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Anthropic Academy</a></li><li><a href="/customers" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Customer stories</a></li><li><a href="/engineering" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Engineering at Anthropic</a></li><li><a href="https://www.anthropic.com/partners/mcp" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">MCP Integrations</a></li><li><a href="/partners/powered-by-claude" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Partner Directory</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Explore</h3><ul class="SiteFooter_list__jhKng"><li><a href="/company" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">About us</a></li><li><a href="https://www.anthropic.com/referral" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Become a partner</a></li><li><a href="/careers" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Careers</a></li><li><a href="/events" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Events</a></li><li><a href="/news" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">News</a></li><li><a href="https://www.anthropic.com/startups" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Startups program</a></li></ul></div></div><div class="SiteFooter_columnSection__UQ8bf"><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Help and security</h3><ul class="SiteFooter_list__jhKng"><li><a href="https://status.anthropic.com/" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Status</a></li><li><a href="/supported-countries" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Availability</a></li><li><a href="https://support.anthropic.com" class="SiteFooter_listItem__unS4r detail-m agate" rel="noopener" target="_blank">Support center</a></li></ul></div><div class="SiteFooter_listSection__FH30K"><h3 class="detail-m bold">Terms and policies</h3><ul class="SiteFooter_list__jhKng"><button class="ConsentContainer_consentButton__iKm9g detail-m agate" tabindex="0">Privacy choices</button><li><a href="/legal/privacy" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Privacy policy</a></li><li><a href="/responsible-disclosure-policy" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Responsible disclosure policy</a></li><li><a href="/legal/consumer-terms" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Terms of service - consumer</a></li><li><a href="/legal/commercial-terms" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Terms of service - commercial</a></li><li><a href="/legal/aup" class="SiteFooter_listItem__unS4r detail-m agate" referrerPolicy="no-referrer-when-downgrade">Usage policy</a></li></ul></div></div></nav></div><div class="SiteFooter_bottomWrapper__MlIbX"><small class="detail-m agate SiteFooter_copyright__YACmd" role="contentinfo">© 2025 Anthropic PBC</small><ul class="SiteFooter_socialIcons__WztHk" role="navigation" aria-label="Social media links"><li><a href="https://www.youtube.com/@anthropic-ai" aria-label="Visit our YouTube channel" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="32" height="32" viewBox="0 0 32 32"><path d="M29.2184 9.4375C28.9596 8.06299 27.7263 7.06201 26.2951 6.74951C24.1533 6.3125 20.1896 6 15.901 6C11.615 6 7.58782 6.3125 5.44354 6.74951C4.01486 7.06201 2.77905 7.99951 2.52021 9.4375C2.25884 11 2 13.1875 2 16C2 18.8125 2.25884 21 2.58365 22.5625C2.84502 23.937 4.0783 24.938 5.50698 25.2505C7.78068 25.6875 11.6784 26 15.967 26C20.2556 26 24.1533 25.6875 26.427 25.2505C27.8557 24.938 29.089 24.0005 29.3504 22.5625C29.6092 21 29.934 18.749 30 16C29.868 13.1875 29.5432 11 29.2184 9.4375ZM12.3941 20.375V11.625L20.319 16L12.3941 20.375Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://www.linkedin.com/company/anthropicresearch" aria-label="Visit our LinkedIn page" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="32" height="32" viewBox="0 0 32 32"><path d="M25.8182 4H6.18182C4.97636 4 4 4.97636 4 6.18182V25.8182C4 27.0236 4.97636 28 6.18182 28H25.8182C27.0236 28 28 27.0236 28 25.8182V6.18182C28 4.97636 27.0236 4 25.8182 4ZM11.5862 23.6364H8.368V13.2815H11.5862V23.6364ZM9.94436 11.8011C8.90691 11.8011 8.068 10.96 8.068 9.92473C8.068 8.88945 8.908 8.04945 9.94436 8.04945C10.9785 8.04945 11.8196 8.89055 11.8196 9.92473C11.8196 10.96 10.9785 11.8011 9.94436 11.8011ZM23.6407 23.6364H20.4247V18.6007C20.4247 17.3996 20.4029 15.8549 18.7524 15.8549C17.0778 15.8549 16.8204 17.1629 16.8204 18.5135V23.6364H13.6044V13.2815H16.6916V14.6964H16.7353C17.1651 13.8825 18.2145 13.024 19.78 13.024C23.0385 13.024 23.6407 15.1687 23.6407 17.9571V23.6364Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://x.com/AnthropicAI" aria-label="Visit our X (formerly Twitter) profile" target="_blank" rel="noopener noreferrer"><svg class="Icon_icon__UdTNj" width="32" height="32" viewBox="0 0 32 32"><path d="M28 28L18.6145 14.0124L18.6305 14.0255L27.0929 4H24.265L17.3713 12.16L11.8968 4H4.48021L13.2425 17.0593L13.2414 17.0582L4 28H6.82792L14.4921 18.9215L20.5834 28H28ZM10.7763 6.18182L23.9449 25.8182H21.7039L8.52468 6.18182H10.7763Z" fill="#b0aea5"></path></svg></a></li></ul></div></div></footer><script src="/_next/static/chunks/webpack-d8dc115719352f34.js" nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx" async=""></script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"1:HL[\"/_next/static/media/01129e8457e4a897-s.p.ttf\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/ttf\"}]\n2:HL[\"/_next/static/media/0a03b2d3f2326303-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/media/177b7db6a26ff4c3-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n4:HL[\"/_next/static/media/2d21c5135ef46b39-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n5:HL[\"/_next/static/media/42c6973fffeb4919-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n6:HL[\"/_next/static/media/4e8887750eb14755-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n7:HL[\"/_next/static/media/5dd0369324c6e67e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n8:HL[\"/_next/static/media/844eb89fa4effbb2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n9:HL[\"/_next/static/media/afcde17c90040887-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\na:HL[\"/_next/static/media/c1cf232a330ed002-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nb:HL[\"/_next/static/media/cfe503504e29ad5d-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nc:HL[\"/_next/static/media/d7440d3c533a1aec-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\nd:HL[\"/_next/static/media/db2277a4dc542e54-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\ne:HL[\"/_next/static/css/9bf880a802bdb80b.css\",\"style\"]\nf:HL[\"/_next/static/css/c590bd4b041dc657.css\",\"style\"]\n10:HL[\"/_next/static/css/2e0d62ccdb367d80.css\",\"style\"]\n11:HL[\"/_next/static/css/1607ca09b8e6c25e.css\",\"style\"]\n12:HL[\"/_next/static/css/0e2a6e211da5747f.css\",\"style\"]\n13:HL[\"/_next/static/css/00a642b57d96adff.css\",\"style\"]\n14:HL[\"/_next/static/css/52994232fd15d79f.css\",\"style\"]\n15:HL[\"/_next/static/css/18b72fe33e784864.css\",\"style\"]\n16:HL[\"/_next/static/css/579a43ce119caf67.css\",\"style\"]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"17:I[95751,[],\"\"]\n1a:I[39275,[],\"\"]\n1c:I[61343,[],\"\"]\n1d:I[42594,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"922\",\"static/chunks/c15bf2b0-805db01d15bd4563.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"6553\",\"static/chunks/6553-ebf326f74c5292d7.js\",\"9450\",\"static/chunks/9450-09246fba0b06068f.js\",\"1204\",\"static/chunks/1204-b63115b25250d7bb.js\",\"9582\",\"static/chunks/9582-0f16bbc87808f931.js\",\"7337\",\"static/chunks/7337-3a2e22eeed3410c4.js\",\"2091\",\"static/chunks/2091-72ee32de691ba886.js\",\"5749\",\"static/chunks/5749-fdb2b822e2252a4a.js\",\"7510\",\"static/chunks/7510-98b0678559316e26.js\",\"6787\",\"static/chunks/6787-f554d19c61e08a1b.js\",\"4062\",\"static/chunks/4062-742ddec75f52b5f2.js\",\"175\",\"static/chunks/app/(site)/%5B%5B...slug%5D%5D/page-097dda26631bad1e.js\"],\"default\"]\n1e:I[24778,[\"8616\",\"static/chunks/8616-254847c413581317.js\",\"7457\",\"static/chunks/app/(site)/layout-3309f2b8a131fb7a.js\"],\"default\"]\n22:I[76130,[],\"\"]\n1b:[\"slug\",\"built-multi-agent-research-system\",\"d\"]\n23:[]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"0:[\"$\",\"$L17\",null,{\"buildId\":\"SJBxveodV1kWHh0jiuQM5\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"engineering\",\"built-multi-agent-research-system\"],\"initialTree\":[\"\",{\"children\":[\"(site)\",{\"children\":[\"engineering\",{\"children\":[[\"slug\",\"built-multi-agent-research-system\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(site)\",{\"children\":[\"engineering\",{\"children\":[[\"slug\",\"built-multi-agent-research-system\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L18\",\"$L19\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2e0d62ccdb367d80.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1607ca09b8e6c25e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0e2a6e211da5747f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/00a642b57d96adff.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"4\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/52994232fd15d79f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"5\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/18b72fe33e784864.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"6\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/579a43ce119caf67.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]],null],null]},[null,[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\",\"engineering\",\"children\",\"$1b\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1c\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[null,[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\",\"engineering\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1c\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c590bd4b041dc657.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L1d\",null,{\"nonce\":\"MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx\",\"children\":[[\"$\",\"$L1e\",null,{}],[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(site)\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1c\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$L1f\",\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2e0d62ccdb367d80.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1607ca09b8e6c25e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/579a43ce119caf67.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}]]}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/9bf880a802bdb80b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],\"$L20\"],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L21\"],\"globalErrorComponent\":\"$22\",\"missingSlots\":\"$W23\"}]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"24:I[83568,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"6553\",\"static/chunks/6553-ebf326f74c5292d7.js\",\"9450\",\"static/chunks/9450-09246fba0b06068f.js\",\"2091\",\"static/chunks/2091-72ee32de691ba886.js\",\"5749\",\"static/chunks/5749-fdb2b822e2252a4a.js\",\"7510\",\"static/chunks/7510-98b0678559316e26.js\",\"8129\",\"static/chunks/app/(site)/engineering/%5Bslug%5D/page-e9f67ae7d0165724.js\"],\"default\"]\n25:I[69335,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"6553\",\"static/chunks/6553-ebf326f74c5292d7.js\",\"2091\",\"static/chunks/2091-72ee32de691ba886.js\",\"5749\",\"static/chunks/5749-fdb2b822e2252a4a.js\",\"7995\",\"static/chunks/app/(site)/not-found-4ae41f9e6f9717e3.js\"],\"default\"]\n26:I[68759,[\"6744\",\"static/chunks/d8e9270f-d57a4faa183a21b3.js\",\"5055\",\"static/chunks/cc3e2e0e-9a8a205950288c5c.js\",\"9573\",\"static/chunks/d8f92815-58bfe84c979b4d69.js\",\"1440\",\"static/chunks/20e9ecfc-2a45032f86ca4c33.js\",\"8815\",\"static/chunks/ccd63cfe-be58d908b1d80a17.js\",\"2331\",\"static/chunks/3204862b-324c96543028037a.js\",\"6583\",\"static/chunks/8ace8c09-2ef1471301516487.js\",\"6990\",\"static/chunks/13b76428-b914bed72c3f2a72.js\",\"8616\",\"static/chunks/8616-254847c413581317.js\",\"6553\",\"static/chunks/6553-ebf326f74c5292d7.js\",\"2091\",\"static/chu"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"nks/2091-72ee32de691ba886.js\",\"5749\",\"static/chunks/5749-fdb2b822e2252a4a.js\",\"7995\",\"static/chunks/app/(site)/not-found-4ae41f9e6f9717e3.js\"],\"default\"]\n20:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_5e9598 __variable_403256 __variable_57fc85 __variable_34e0db __variable_862ba3\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1c\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}]}]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"19:[\"$\",\"$L24\",null,{\"article\":{\"_createdAt\":\"2025-04-22T15:57:19Z\",\"_id\":\"4d839e4f-bbc6-46f3-acff-dbfb9feb47aa\",\"_rev\":\"jaBadZdeECTuIR9BYptEGe\",\"_type\":\"engineeringArticle\",\"_updatedAt\":\"2025-06-14T22:29:42Z\",\"body\":[{\"_key\":\"5c080240651b\",\"_type\":\"block\",\"children\":[{\"_key\":\"f1f1c08fee930\",\"_type\":\"span\",\"marks\":[],\"text\":\"Claude now has \"},{\"_key\":\"f1f1c08fee931\",\"_type\":\"span\",\"marks\":[\"ed36721945b5\"],\"text\":\"Research capabilities\"},{\"_key\":\"f1f1c08fee932\",\"_type\":\"span\",\"marks\":[],\"text\":\" that allow it to search across the web, Google Workspace, and any integrations to accomplish complex tasks.\"}],\"markDefs\":[{\"_key\":\"ed36721945b5\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/news/research\"}],\"style\":\"normal\"},{\"_key\":\"f4f143e74642\",\"_type\":\"block\",\"children\":[{\"_key\":\"71c0ff6d5df30\",\"_type\":\"span\",\"marks\":[],\"text\":\"The journey of this multi-agent system from prototype to production taught us critical lessons about system architecture, tool design, and prompt engineering. A multi-agent system consists of multiple agents (LLMs autonomously using tools in a loop) working together. Our Research feature involves an agent that plans a research process based on user queries, and then uses tools to create parallel agents that search for information simultaneously. Systems with multiple agents introduce new challenges in agent coordination, evaluation, and reliability. \"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"09fbfb5ce775\",\"_type\":\"block\",\"children\":[{\"_key\":\"85d112e80759\",\"_type\":\"span\",\"marks\":[],\"text\":\"This post breaks down the principles that worked for us—we hope you'll find them useful to apply when building your own multi-agent systems.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e586e389cfd5\",\"_type\":\"block\",\"children\":[{\"_key\":\"bbfb7acdf6500\",\"_type\":\"span\",\"marks\":[],\"text\":\"Benefits of a multi-agent system\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"f2478902225d\",\"_type\":\"block\",\"children\":[{\"_key\":\"7ba81741b4c40\",\"_type\":\"span\",\"marks\":[],\"text\":\"Research work involves open-ended problems where it’s very difficult to predict the required steps in advance. You can’t hardcode a fixed path for exploring complex topics, as the process is inherently dynamic and path-dependent. When people conduct research, they tend to continuously update their approach based on discoveries, following leads that emerge during investigation.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2fb3cf7bb106\",\"_type\":\"block\",\"children\":[{\"_key\":\"a2c4bafc4b430\",\"_type\":\"span\",\"marks\":[],\"text\":\"This unpredictability makes AI agents particularly well-suited for research tasks. Research demands the flexibility to pivot or explore tangential connections as the investigation unfolds. The model must operate autonomously for many turns, making decisions about which directions to pursue based on intermediate findings. A linear, one-shot pipeline cannot handle these tasks.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"759f699d3fc4\",\"_type\":\"block\",\"children\":[{\"_key\":\"6207d3083a680\",\"_type\":\"span\",\"marks\":[],\"text\":\"The essence of search is compression: distilling insights from a vast corpus. Subagents facilitate compression by operating in parallel with their own context windows, exploring different aspects of the question simultaneously before condensing the most important tokens for the lead research agent. Each subagent also provides separation of concerns—distinct tools, prompts, and exploration trajectories—which reduces path dependency and enables thorough, independent investigations.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8ae13574d74e\",\"_type\":\"block\",\"children\":[{\"_key\":\"473dbfc33b350\",\"_type\":\"span\",\"marks\":[],\"text\":\"Once intelligence reaches a threshold, multi-agent systems become a vital way to scale performance. For instance, although individual humans have become more intelligent in the last 100,000 years, human societies have become \"},{\"_key\":\"26c2149361a2\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"exponentially\"},{\"_key\":\"886e8e02ab50\",\"_type\":\"span\",\"marks\":[],\"text\":\" more capable in the information age because of our \"},{\"_key\":\"a7e13c335c9b\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"collective\"},{\"_key\":\"89877b0808cd\",\"_type\":\"span\",\"marks\":[],\"text\":\" intelligence and ability to coordinate. Even generally-intelligent agents face limits when operating as individuals; groups of agents can accomplish far more.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"4a9eeb372b63\",\"_type\":\"block\",\"children\":[{\"_key\":\"2eedbed0271c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our internal evaluations show that multi-agent research systems excel especially for breadth-first queries that involve pursuing multiple independent directions simultaneously. We found that a multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on our internal research eval. For example, when asked to identify all the board members of the companies in the Information Technology S\u0026P 500, the multi-agent system found the correct answers by decomposing this into tasks for subagents, while the single agent system failed to find the answer with slow, sequential searches.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"92ad8ad2ac7e\",\"_type\":\"block\",\"children\":[{\"_key\":\"ed3cc85d97fd0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Multi-agent systems work mainly because they help spend enough tokens to solve the problem. In our analysis, three factors explained 95% of the performance variance in the \"},{\"_key\":\"ed3cc85d97fd1\",\"_type\":\"span\",\"marks\":[\"225bd0ab3e45\"],\"text\":\"BrowseComp\"},{\"_key\":\"ed3cc85d97fd2\",\"_type\":\"span\",\"marks\":[],\"text\":\" evaluation (which tests the ability of browsing agents to locate hard-to-find information). We found that token usage by itself explains 80% of the variance, with the number of tool calls and the model choice as the two other explanatory factors. This finding validates our architecture that distributes work across agents with separate context windows to add more capacity for parallel reasoning. The latest Claude models act as large efficiency multipliers on token use, as upgrading to Claude Sonnet 4 is a larger performance gain than doubling the token budget on Claude Sonnet 3.7. Multi-agent architectures effectively scale token usage for tasks that exceed the limits of single agents.\"}],\"markDefs\":[{\"_key\":\"225bd0ab3e45\",\"_type\":\"link\",\"href\":\"https://openai.com/index/browsecomp/\"}],\"style\":\"normal\"},{\"_key\":\"c8eb17de5e21\",\"_type\":\"block\",\"children\":[{\"_key\":\"39f11a70e2c50\",\"_type\":\"span\",\"marks\":[],\"text\":\"There is a downside: in practice, these architectures burn through tokens fast. In our data, agents typically use about 4× more tokens than chat interactions, and multi-agent systems use about 15× more tokens than chats. For economic viability, multi-agent systems require tasks where the value of the task is high enough to pay for the increased performance. Further, some domains that require all agents to share the same context or involve many dependencies between agents are not a good fit for multi-agent systems today. For instance, most coding tasks involve fewer truly parallelizable tasks than research, and LLM agents are not yet great at coordinating and delegating to other agents in real time. We’ve found that multi-agent systems excel at valuable tasks that involve heavy parallelization, information that exceeds single context windows, and interfacing with numerous complex tools.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b5e700f11d61\",\"_type\":\"block\",\"children\":[{\"_key\":\"b475a127e1570\",\"_type\":\"span\",\"marks\":[],\"text\":\"Architecture overview for Research\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"cc8767a567a7\",\"_type\":\"block\",\"children\":[{\"_key\":\"04ecab4d95120\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our Research system uses a multi-agent architecture with an orchestrator-worker pattern, where a lead agent coordinates the process while delegating to specialized subagents that operate in parallel.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"578faa41f4f7\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"a1015dc0f7a5\",\"_type\":\"block\",\"children\":[{\"_key\":\"aaadab2d1baf0\",\"_type\":\"span\",\"marks\":[],\"text\":\"The multi-agent architecture in action: user queries flow through a lead agent that creates specialized subagents to search for different aspects in parallel.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2579,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png\",\"width\":4584},{\"_key\":\"299e21309264\",\"_type\":\"block\",\"children\":[{\"_key\":\"7b801b89ef8f0\",\"_type\":\"span\",\"marks\":[],\"text\":\"When a user submits a query, the lead agent analyzes it, develops a strategy, and spawns subagents to explore different aspects simultaneously. As shown in the diagram above, the subagents act as intelligent filters by iteratively using search tools to gather information, in this case on AI agent companies in 2025, and then returning a list of companies to the lead agent so it can compile a final answer.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9dc616952696\",\"_type\":\"block\",\"children\":[{\"_key\":\"a61496818ab00\",\"_type\":\"span\",\"marks\":[],\"text\":\"Traditional approaches using Retrieval Augmented Generation (RAG) use static retrieval. That is, they fetch some set of chunks that are most similar to an input query and use these chunks to generate a response. In contrast, our architecture uses a multi-step search that dynamically finds relevant information, adapts to new findings, and analyzes results to formulate high-quality answers.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6c77e5e40830\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"6fe34f741144\",\"_type\":\"block\",\"children\":[{\"_key\":\"5063be0096ea0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Process diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any number) with specific research tasks. Each Subagent independently performs web searches, evaluates tool results using \"},{\"_key\":\"5063be0096ea1\",\"_type\":\"span\",\"marks\":[\"5b0bee84df77\"],\"text\":\"interleaved thinking\"},{\"_key\":\"5063be0096ea2\",\"_type\":\"span\",\"marks\":[],\"text\":\", and returns findings to the LeadResearcher. The LeadResearcher synthesizes these results and decides whether more research is needed—if so, it can create additional subagents or refine its strategy. Once sufficient information is gathered, the system exits the research loop and passes all findings to a CitationAgent, which processes the documents and research report to identify specific locations for citations. This ensures all claims are properly attributed to their sources. The final research results, complete with citations, are then returned to the user.\"}],\"markDefs\":[{\"_key\":\"5b0bee84df77\",\"_type\":\"link\",\"href\":\"https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking\"}],\"style\":\"normal\"}],\"height\":4584,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png\",\"width\":4584},{\"_key\":\"2dbfd80275da\",\"_type\":\"block\",\"children\":[{\"_key\":\"8b5c4465633f0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Prompt engineering and evaluations for research agents\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"f8e82ff164a8\",\"_type\":\"block\",\"children\":[{\"_key\":\"8fc2bc857cb80\",\"_type\":\"span\",\"marks\":[],\"text\":\"Multi-agent systems have key differences from single-agent systems, including a rapid growth in coordination complexity. Early agents made errors like spawning 50 subagents for simple queries, scouring the web endlessly for nonexistent sources, and distracting each other with excessive updates. Since each agent is steered by a prompt, prompt engineering was our primary lever for improving these behaviors. Below are some principles we learned for prompting agents:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f0dd2f9583f6\",\"_type\":\"block\",\"children\":[{\"_key\":\"36ff76bca61e0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Think like your agents. \"},{\"_key\":\"36ff76bca61e1\",\"_type\":\"span\",\"marks\":[],\"text\":\"To iterate on prompts, you must understand their effects. To help us do this, we built simulations using our \"},{\"_key\":\"36ff76bca61e2\",\"_type\":\"span\",\"marks\":[\"ad6b4097506f\"],\"text\":\"Console\"},{\"_key\":\"36ff76bca61e3\",\"_type\":\"span\",\"marks\":[],\"text\":\" with the exact prompts and tools from our system, then watched agents work step-by-step. This immediately revealed failure modes: agents continuing when they already had sufficient results, using overly verbose search queries, or selecting incorrect tools. Effective prompting relies on developing an accurate mental model of the agent, which can make the most impactful changes obvious.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[{\"_key\":\"ad6b4097506f\",\"_type\":\"link\",\"href\":\"https://console.anthropic.com/\"}],\"style\":\"normal\"},{\"_key\":\"cab1c4f50766\",\"_type\":\"block\",\"children\":[{\"_key\":\"df339e010fce0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Teach the orchestrator how to delegate.\"},{\"_key\":\"df339e010fce1\",\"_type\":\"span\",\"marks\":[],\"text\":\" In our system, the lead agent decomposes queries into subtasks and describes them to subagents. Each subagent needs an objective, an output format, guidance on the tools and sources to use, and clear task boundaries. Without detailed task descriptions, agents duplicate work, leave gaps, or fail to find necessary information. We started by allowing the lead agent to give simple, short instructions like 'research the semiconductor shortage,' but found these instructions often were vague enough that subagents misinterpreted the task or performed the exact same searches as other agents. For instance, one subagent explored the 2021 automotive chip crisis while 2 others duplicated work investigating current 2025 supply chains, without an effective division of labor.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"369319a9b1f8\",\"_type\":\"block\",\"children\":[{\"_key\":\"83f1c4dc36c10\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Scale effort to query complexity. \"},{\"_key\":\"83f1c4dc36c11\",\"_type\":\"span\",\"marks\":[],\"text\":\"Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries, which was a common failure mode in our early versions.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d5436ace3e27\",\"_type\":\"block\",\"children\":[{\"_key\":\"2cd3ad84d6ce0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Tool design and selection are critical. \"},{\"_key\":\"2cd3ad84d6ce1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Agent-tool interfaces are as critical as human-computer interfaces. Using the right tool is efficient—often, it’s strictly necessary. For instance, an agent searching the web for context that only exists in Slack is doomed from the start. With \"},{\"_key\":\"2cd3ad84d6ce2\",\"_type\":\"span\",\"marks\":[\"ff19654c62d1\"],\"text\":\"MCP servers\"},{\"_key\":\"2cd3ad84d6ce3\",\"_type\":\"span\",\"marks\":[],\"text\":\" that give the model access to external tools, this problem compounds, as agents encounter unseen tools with descriptions of wildly varying quality. We gave our agents explicit heuristics: for example, examine all available tools first, match tool usage to user intent, search the web for broad external exploration, or prefer specialized tools over generic ones. Bad tool descriptions can send agents down completely wrong paths, so each tool needs a distinct purpose and a clear description.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[{\"_key\":\"ff19654c62d1\",\"_type\":\"link\",\"href\":\"https://modelcontextprotocol.io/introduction\"}],\"style\":\"normal\"},{\"_key\":\"1e2b92729370\",\"_type\":\"block\",\"children\":[{\"_key\":\"11fd566106df0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Let agents improve themselves\"},{\"_key\":\"11fd566106df1\",\"_type\":\"span\",\"marks\":[],\"text\":\". We found that the Claude 4 models can be excellent prompt engineers. When given a prompt and a failure mode, they are able to diagnose why the agent is failing and suggest improvements. We even created a tool-testing agent—when given a flawed MCP tool, it attempts to use the tool and then rewrites the tool description to avoid failures. By testing the tool dozens of times, this agent found key nuances and bugs. This process for improving tool ergonomics resulted in a 40% decrease in task completion time for future agents using the new description, because they were able to avoid most mistakes.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"72067183fa56\",\"_type\":\"block\",\"children\":[{\"_key\":\"4dc544d622f50\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Start wide, then narrow down.\"},{\"_key\":\"4dc544d622f51\",\"_type\":\"span\",\"marks\":[],\"text\":\" Search strategy should mirror expert human research: explore the landscape before drilling into specifics. Agents often default to overly long, specific queries that return few results. We counteracted this tendency by prompting agents to start with short, broad queries, evaluate what’s available, then progressively narrow focus.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b94828c29fbd\",\"_type\":\"block\",\"children\":[{\"_key\":\"146d1ae0a1fc0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Guide the thinking process.\"},{\"_key\":\"146d1ae0a1fc1\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"146d1ae0a1fc2\",\"_type\":\"span\",\"marks\":[\"d4a8cbbede45\"],\"text\":\"Extended thinking mode\"},{\"_key\":\"146d1ae0a1fc3\",\"_type\":\"span\",\"marks\":[],\"text\":\", which leads Claude to output additional tokens in a visible thinking process, can serve as a controllable scratchpad. The lead agent uses thinking to plan its approach, assessing which tools fit the task, determining query complexity and subagent count, and defining each subagent’s role. Our testing showed that extended thinking improved instruction-following, reasoning, and efficiency. Subagents also plan, then use \"},{\"_key\":\"146d1ae0a1fc4\",\"_type\":\"span\",\"marks\":[\"f173662c0a6e\"],\"text\":\"interleaved thinking\"},{\"_key\":\"146d1ae0a1fc5\",\"_type\":\"span\",\"marks\":[],\"text\":\" after tool results to evaluate quality, identify gaps, and refine their next query. This makes subagents more effective in adapting to any task.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[{\"_key\":\"d4a8cbbede45\",\"_type\":\"link\",\"href\":\"https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking\"},{\"_key\":\"f173662c0a6e\",\"_type\":\"link\",\"href\":\"https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking\"}],\"style\":\"normal\"},{\"_key\":\"cb0dbc07c16d\",\"_type\":\"block\",\"children\":[{\"_key\":\"2a59746a17150\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Parallel tool calling transforms speed and performance.\"},{\"_key\":\"2a59746a17151\",\"_type\":\"span\",\"marks\":[],\"text\":\" Complex research tasks naturally involve exploring many sources. Our early agents executed sequential searches, which was painfully slow. For speed, we introduced two kinds of parallelization: (1) the lead agent spins up 3-5 subagents in parallel rather than serially; (2) the subagents use 3+ tools in parallel. These changes cut research time by up to 90% for complex queries, allowing Research to do more work in minutes instead of hours while covering more information than other systems.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"467632113fb1\",\"_type\":\"block\",\"children\":[{\"_key\":\"4c42363418fa0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our prompting strategy focuses on instilling good heuristics rather than rigid rules. We studied how skilled humans approach research tasks and encoded these strategies in our prompts—strategies like decomposing difficult questions into smaller tasks, carefully evaluating the quality of sources, adjusting search approaches based on new information, and recognizing when to focus on depth (investigating one topic in detail) vs. breadth (exploring many topics in parallel). We also proactively mitigated unintended side effects by setting explicit guardrails to prevent the agents from spiraling out of control. Finally, we focused on a fast iteration loop with observability and test cases.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"91b20fd3eab9\",\"_type\":\"block\",\"children\":[{\"_key\":\"19ca25ca11ac0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Effective evaluation of agents\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"960d6db31b91\",\"_type\":\"block\",\"children\":[{\"_key\":\"45410bce9e430\",\"_type\":\"span\",\"marks\":[],\"text\":\"Good evaluations are essential for building reliable AI applications, and agents are no different. However, evaluating multi-agent systems presents unique challenges. Traditional evaluations often assume that the AI follows the same steps each time: given input X, the system should follow path Y to produce output Z. But multi-agent systems don't work this way. Even with identical starting points, agents might take completely different valid paths to reach their goal. One agent might search three sources while another searches ten, or they might use different tools to find the same answer. Because we don’t always know what the right steps are, we usually can't just check if agents followed the “correct” steps we prescribed in advance. Instead, we need flexible evaluation methods that judge whether agents achieved the right outcomes while also following a reasonable process.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3dce814ef006\",\"_type\":\"block\",\"children\":[{\"_key\":\"db2841e23e0d0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Start evaluating immediately with small samples\"},{\"_key\":\"db2841e23e0d1\",\"_type\":\"span\",\"marks\":[],\"text\":\". In early agent development, changes tend to have dramatic impacts because there is abundant low-hanging fruit. A prompt tweak might boost success rates from 30% to 80%. With effect sizes this large, you can spot changes with just a few test cases. We started with a set of about 20 queries representing real usage patterns. Testing these queries often allowed us to clearly see the impact of changes. We often hear that AI developer teams delay creating evals because they believe that only large evals with hundreds of test cases are useful. However, it’s best to start with small-scale testing right away with a few examples, rather than delaying until you can build more thorough evals.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ce8c2a6c9460\",\"_type\":\"block\",\"children\":[{\"_key\":\"849a944596aa0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"LLM-as-judge evaluation scales when done well.\"},{\"_key\":\"849a944596aa1\",\"_type\":\"span\",\"marks\":[],\"text\":\" Research outputs are difficult to evaluate programmatically, since they are free-form text and rarely have a single correct answer. LLMs are a natural fit for grading outputs. We used an LLM judge that evaluated each output against criteria in a rubric: factual accuracy (do claims match sources?), citation accuracy (do the cited sources match the claims?), completeness (are all requested aspects covered?), source quality (did it use primary sources over lower-quality secondary sources?), and tool efficiency (did it use the right tools a reasonable number of times?). We experimented with multiple judges to evaluate each component, but found that a single LLM call with a single prompt outputting scores from 0.0-1.0 and a pass-fail grade was the most consistent and aligned with human judgements. This method was especially effective when the eval test cases \"},{\"_key\":\"849a944596aa2\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"did\"},{\"_key\":\"849a944596aa3\",\"_type\":\"span\",\"marks\":[],\"text\":\" have a clear answer, and we could use the LLM judge to simply check if the answer was correct (i.e. did it accurately list the pharma companies with the top 3 largest R\u0026D budgets?). Using an LLM as a judge allowed us to scalably evaluate hundreds of outputs.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ab632ed22dd7\",\"_type\":\"block\",\"children\":[{\"_key\":\"a5838b7b22710\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Human evaluation catches what automation misses.\"},{\"_key\":\"a5838b7b22711\",\"_type\":\"span\",\"marks\":[],\"text\":\" People testing agents find edge cases that evals miss. These include hallucinated answers on unusual queries, system failures, or subtle source selection biases. In our case, human testers noticed that our early agents consistently chose SEO-optimized content farms over authoritative but less highly-ranked sources like academic PDFs or personal blogs. Adding source quality heuristics to our prompts helped resolve this issue. Even in a world of automated evaluations, manual testing remains essential.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6cb72c70a913\",\"_type\":\"block\",\"children\":[{\"_key\":\"4f762c5326090\",\"_type\":\"span\",\"marks\":[],\"text\":\"Multi-agent systems have emergent behaviors, which arise without specific programming. For instance, small changes to the lead agent can unpredictably change how subagents behave. Success requires understanding interaction patterns, not just individual agent behavior. Therefore, the best prompts for these agents are not just strict instructions, but frameworks for collaboration that define the division of labor, problem-solving approaches, and effort budgets. Getting this right relies on careful prompting and tool design, solid heuristics, observability, and tight feedback loops.\"},{\"_key\":\"4f762c5326091\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\" \"},{\"_key\":\"4f762c5326092\",\"_type\":\"span\",\"marks\":[],\"text\":\"See the \"},{\"_key\":\"6df36095f40e\",\"_type\":\"span\",\"marks\":[\"ae1b0d2fb01c\"],\"text\":\"open-source prompts in our Cookbook\"},{\"_key\":\"320263e91ddf\",\"_type\":\"span\",\"marks\":[],\"text\":\" for example prompts from our system.\"}],\"markDefs\":[{\"_key\":\"ae1b0d2fb01c\",\"_type\":\"link\",\"blank\":false,\"href\":\"https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts\"}],\"style\":\"normal\"},{\"_key\":\"52b1cf275124\",\"_type\":\"block\",\"children\":[{\"_key\":\"af5afdc1dcb90\",\"_type\":\"span\",\"marks\":[],\"text\":\"Production reliability and engineering challenges\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"63ecee551c8b\",\"_type\":\"block\",\"children\":[{\"_key\":\"055a66faa8bf0\",\"_type\":\"span\",\"marks\":[],\"text\":\"In traditional software, a bug might break a feature, degrade performance, or cause outages. In agentic systems, minor changes cascade into large behavioral changes, which makes it remarkably difficult to write code for complex agents that must maintain state in a long-running process.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"285237409cbb\",\"_type\":\"block\",\"children\":[{\"_key\":\"4831d15ce4660\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Agents are stateful and errors compound. \"},{\"_key\":\"4831d15ce4661\",\"_type\":\"span\",\"marks\":[],\"text\":\"Agents can run for long periods of time, maintaining state across many tool calls. This means we need to durably execute code and handle errors along the way. Without effective mitigations, minor system failures can be catastrophic for agents. When errors occur, we can't just restart from the beginning: restarts are expensive and frustrating for users. Instead, we built systems that can resume from where the agent was when the errors occurred. We also use the model’s intelligence to handle issues gracefully: for instance, letting the agent know when a tool is failing and letting it adapt works surprisingly well. We combine the adaptability of AI agents built on Claude with deterministic safeguards like retry logic and regular checkpoints.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fdf19ff73848\",\"_type\":\"block\",\"children\":[{\"_key\":\"1f1a56cf7fdb0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Debugging benefits from new approaches. \"},{\"_key\":\"1f1a56cf7fdb1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Agents make dynamic decisions and are non-deterministic between runs, even with identical prompts. This makes debugging harder. For instance, users would report agents “not finding obvious information,” but we couldn't see why. Were the agents using bad search queries? Choosing poor sources? Hitting tool failures? Adding full production tracing let us diagnose why agents failed and fix issues systematically. Beyond standard observability, we monitor agent decision patterns and interaction structures—all without monitoring the contents of individual conversations, to maintain user privacy. This high-level observability helped us diagnose root causes, discover unexpected behaviors, and fix common failures.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"dfef316b5cf7\",\"_type\":\"block\",\"children\":[{\"_key\":\"e03e04c3bd8e0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Deployment needs careful coordination.\"},{\"_key\":\"e03e04c3bd8e1\",\"_type\":\"span\",\"marks\":[],\"text\":\" Agent systems are highly stateful webs of prompts, tools, and execution logic that run almost continuously. This means that whenever we deploy updates, agents might be anywhere in their process. We therefore need to prevent our well-meaning code changes from breaking existing agents. We can’t update every agent to the new version at the same time. Instead, we use \"},{\"_key\":\"e03e04c3bd8e2\",\"_type\":\"span\",\"marks\":[\"f4b582db8fc8\"],\"text\":\"rainbow deployments\"},{\"_key\":\"e03e04c3bd8e3\",\"_type\":\"span\",\"marks\":[],\"text\":\" to avoid disrupting running agents, by gradually shifting traffic from old to new versions while keeping both running simultaneously.\"}],\"markDefs\":[{\"_key\":\"f4b582db8fc8\",\"_type\":\"link\",\"href\":\"https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/\"}],\"style\":\"normal\"},{\"_key\":\"355f209cab85\",\"_type\":\"block\",\"children\":[{\"_key\":\"386b0345f8df0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Synchronous execution creates bottlenecks.\"},{\"_key\":\"386b0345f8df1\",\"_type\":\"span\",\"marks\":[],\"text\":\" Currently, our lead agents execute subagents synchronously, waiting for each set of subagents to complete before proceeding. This simplifies coordination, but creates bottlenecks in the information flow between agents. For instance, the lead agent can’t steer subagents, subagents can’t coordinate, and the entire system can be blocked while waiting for a single subagent to finish searching. Asynchronous execution would enable additional parallelism: agents working concurrently and creating new subagents when needed. But this asynchronicity adds challenges in result coordination, state consistency, and error propagation across the subagents. As models can handle longer and more complex research tasks, we expect the performance gains will justify the complexity.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"bd65cedeaadc\",\"_type\":\"block\",\"children\":[{\"_key\":\"32e76d0095390\",\"_type\":\"span\",\"marks\":[],\"text\":\"Conclusion\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"60ee5a1dfea5\",\"_type\":\"block\",\"children\":[{\"_key\":\"c874ac3de7f90\",\"_type\":\"span\",\"marks\":[],\"text\":\"When building AI agents, the last mile often becomes most of the journey. Codebases that work on developer machines require significant engineering to become reliable production systems. The compound nature of errors in agentic systems means that minor issues for traditional software can derail agents entirely. One step failing can cause agents to explore entirely different trajectories, leading to unpredictable outcomes. For all the reasons described in this post, the gap between prototype and production is often wider than anticipated.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"846775bb71d7\",\"_type\":\"block\",\"children\":[{\"_key\":\"cb5281a95c650\",\"_type\":\"span\",\"marks\":[],\"text\":\"Despite these challenges, multi-agent systems have proven valuable for open-ended research tasks. Users have said that Claude helped them find business opportunities they hadn’t considered, navigate complex healthcare options, resolve thorny technical bugs, and save up to days of work by uncovering research connections they wouldn't have found alone. Multi-agent research systems can operate reliably at scale with careful engineering, comprehensive testing, detail-oriented prompt and tool design, robust operational practices, and tight collaboration between research, product, and engineering teams who have a strong understanding of current agent capabilities. We're already seeing these systems transform how people solve complex problems.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3d9e7090ccfd\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"75d6a4352d32\",\"_type\":\"block\",\"children\":[{\"_key\":\"e34b1c0085150\",\"_type\":\"span\",\"marks\":[],\"text\":\"A \"},{\"_key\":\"e34b1c0085151\",\"_type\":\"span\",\"marks\":[\"f0fb1c03e196\"],\"text\":\"Clio\"},{\"_key\":\"e34b1c0085152\",\"_type\":\"span\",\"marks\":[],\"text\":\" embedding plot showing the most common ways people are using the Research feature today. The top use case categories are developing software systems across specialized domains (10%), develop and optimize professional and technical content (8%), develop business growth and revenue generation strategies (8%), assist with academic research and educational material development (7%), and research and verify information about people, places, or organizations (5%).\"}],\"markDefs\":[{\"_key\":\"f0fb1c03e196\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research/clio\"}],\"style\":\"normal\"}],\"height\":2148,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png\",\"width\":2654},{\"_key\":\"9e90ab52b401\",\"_type\":\"block\",\"children\":[{\"_key\":\"f885c87db4cc\",\"_type\":\"span\",\"marks\":[],\"text\":\"Acknowlegements\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"fd95812180f9\",\"_type\":\"block\",\"children\":[{\"_key\":\"8770aa293a23\",\"_type\":\"span\",\"marks\":[],\"text\":\"Written by Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, and Daniel Ford. This work reflects the collective efforts of several teams across Anthropic who made the Research feature possible. Special thanks go to the Anthropic apps engineering team, whose dedication brought this complex multi-agent system to production. We're also grateful to our early users for their excellent feedback.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5708081699ff\",\"_type\":\"block\",\"children\":[{\"_key\":\"d823d8933d220\",\"_type\":\"span\",\"marks\":[],\"text\":\"Appendix\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"f05502d1981d\",\"_type\":\"block\",\"children\":[{\"_key\":\"8e067077a7220\",\"_type\":\"span\",\"marks\":[],\"text\":\"Below are some additional miscellaneous tips for multi-agent systems.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3bc9c67924d5\",\"_type\":\"block\",\"children\":[{\"_key\":\"1b1896fbc7690\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"End-state evaluation of agents that mutate state over many turns. \"},{\"_key\":\"1b1896fbc7691\",\"_type\":\"span\",\"marks\":[],\"text\":\"Evaluating agents that modify persistent state across multi-turn conversations presents unique challenges. Unlike read-only research tasks, each action can change the environment for subsequent steps, creating dependencies that traditional evaluation methods struggle to handle. We found success focusing on end-state evaluation rather than turn-by-turn analysis. Instead of judging whether the agent followed a specific process, evaluate whether it achieved the correct final state. This approach acknowledges that agents may find alternative paths to the same goal while still ensuring they deliver the intended outcome. For complex workflows, break evaluation into discrete checkpoints where specific state changes should have occurred, rather than attempting to validate every intermediate step.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"94734f3d5fb1\",\"_type\":\"block\",\"children\":[{\"_key\":\"c79c4eed3f5a0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Long-horizon conversation management. \"},{\"_key\":\"c79c4eed3f5a1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Production agents often engage in conversations spanning hundreds of turns, requiring careful context management strategies. As conversations extend, standard context windows become insufficient, necessitating intelligent compression and memory mechanisms. We implemented patterns where agents summarize completed work phases and store essential information in external memory before proceeding to new tasks. When context limits approach, agents can spawn fresh subagents with clean contexts while maintaining continuity through careful handoffs. Further, they can retrieve stored context like the research plan from their memory rather than losing previous work when reaching the context limit. This distributed approach prevents context overflow while preserving conversation coherence across extended interactions.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"da715aef7e10\",\"_type\":\"block\",\"children\":[{\"_key\":\"6d280c91ef880\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Subagent output to a filesystem to minimize the ‘game of telephone.’ \"},{\"_key\":\"6d280c91ef881\",\"_type\":\"span\",\"marks\":[],\"text\":\"Direct subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. This prevents information loss during multi-stage processing and reduces token overhead from copying large outputs through conversation history. The pattern works particularly well for structured outputs like code, reports, or data visualizations where the subagent's specialized prompt produces better results than filtering through a general coordinator.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"cardImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000-svg\",\"_type\":\"reference\"},\"height\":1000,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000.svg\",\"width\":1000},\"hero\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000-svg\",\"_type\":\"reference\"},\"caption\":null,\"height\":1000,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000.svg\",\"width\":1000},\"meta\":{\"robotsIndexable\":true,\"seoDescription\":\"On the the engineering challenges and lessons learned from building Claude's Research system\",\"seoTitle\":\"How we built our multi-agent research system\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-04-22T16:47:38Z\",\"_id\":\"image-5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260-png\",\"_rev\":\"xn9zAYek4ZGpTrsbzaZv7F\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-04-22T16:47:38Z\",\"assetId\":\"5cf046fff69b847bfa78c12723dd466b285c0218\",\"extension\":\"png\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MGQ,H-t7~px[9Gx[f6ofkCWB?bj[9Gay%M\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":true,\"isOpaque\":true,\"lqip\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABR0lEQVR4nJWTS0/CQBSF+eMuZMHKTU0UjEVtjA5GXkqkKgEkGhWDii0I5SFY7IPSluofOKYjgosKdHFzM7kz35w790zAsVV4xedYm8bvmtYsxXO/M4nAfwVrNMBQ60FX36ApXWhqD0NDhml+YDwHGvBS5h547zVQvrtCqXiBYoHH7X0JQreGjtqFMZL9KRxbCpqvz0glCNjtDUTZMOInx8g/3qDSFqDofZ9AW0Wj/oQjwmGdWUNkk8Eh4XCQIOALPGS5NXtTexFw0rILTCdj2Nvdwj7H0hwKBcGyYXRaIr4c3V/LUqOK82yatp05jSNGOARXVxAJMxS4vEL7B9iWBOQuM+DPUrgu5VDIZ7ETjSCZIJD70nR4zrK2UQZtiMIDhGoZUvOFqqqJFXqRaficshu2qVAvuofdbLv+m2PohcDZb1kM+Qv8BjJjHCbOrJ7UAAAAAElFTkSuQmCC\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#443c3a\",\"foreground\":\"#fff\",\"population\":0.04,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#733f11\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#abd0c7\",\"foreground\":\"#000\",\"population\":0.19,\"title\":\"#fff\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#abd0c7\",\"foreground\":\"#000\",\"population\":0.19,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcf3eb\",\"foreground\":\"#000\",\"population\":0.15,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c6c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#dd7921\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/png\",\"originalFilename\":\"eng-blog-social-4.png\",\"path\":\"images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png\",\"sha1hash\":\"5cf046fff69b847bfa78c12723dd466b285c0218\",\"size\":47522,\"uploadId\":\"rdTjJ47IbGMpB7cIdNK93ps8ujwTWQfn\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png\"}}},\"publishedOn\":\"2025-06-13\",\"slug\":{\"_type\":\"slug\",\"current\":\"built-multi-agent-research-system\"},\"spotIllustration\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-848e961961a97ada3a7edb2d1d17378792c3288d-500x500-svg\",\"_type\":\"reference\"},\"height\":500,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/848e961961a97ada3a7edb2d1d17378792c3288d-500x500.svg\",\"width\":500},\"subjects\":[{\"_key\":\"architecture\",\"_type\":\"tag\",\"label\":\"Architecture\",\"value\":\"architecture\"}],\"summary\":\"Our Research feature uses multiple Claude agents to explore complex topics more effectively. We share the engineering challenges and the lessons we learned from building this system.\",\"title\":\"How we built our multi-agent research system\"},\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"DElaXo1A74rjItEmVcn9bL\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"zaypqwxsSibfVwOwoBcVU7\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2025-07-17T22:34:08Z\",\"announcement\":null,\"copyright\":\"© 2025 Anthropic PBC\",\"footerLinks\":[{\"_key\":\"7299741de33c\",\"links\":[{\"_key\":\"a5082bfd9e4d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude overview\",\"url\":\"/claude\"},{\"_key\":\"a7a819d6de49\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude Code\",\"url\":\"/claude-code\"},{\"_key\":\"4269e8ecebc8409bdb4b05e05bee85b8\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Max plan\",\"url\":\"/max\"},{\"_key\":\"ee78393233bc\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Team plan\",\"url\":\"/team\"},{\"_key\":\"14e1a3c222e9\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Enterprise plan\",\"url\":\"/enterprise\"},{\"_key\":\"7aa63ef4a4aa\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Download Claude apps\",\"url\":\"https://claude.ai/download\"},{\"_key\":\"5459b2c57b97\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude.ai pricing plans\",\"url\":\"/pricing\"},{\"_key\":\"f3fd0e46d1a3\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Claude.ai login\",\"url\":\"http://claude.ai/login\"}],\"title\":\"Product\"},{\"_key\":\"785d9820a620\",\"links\":[{\"_key\":\"44287b42495c\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"API overview\",\"url\":\"/api\"},{\"_key\":\"f062f9193e7d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Developer docs\",\"url\":\"https://docs.anthropic.com/\"},{\"_key\":\"5bd32b4b104f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude in Amazon Bedrock\",\"url\":\"/amazon-bedrock\"},{\"_key\":\"34544a290d87\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude on Google Cloud's Vertex AI\",\"url\":\"/google-cloud-vertex-ai\"},{\"_key\":\"40a59f463410\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Pricing\",\"url\":\"/pricing#api\"},{\"_key\":\"4cf4c434288c\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Console login\",\"url\":\"https://console.anthropic.com/\"}],\"title\":\"API Platform\"},{\"_key\":\"2c41834b2ec3\",\"links\":[{\"_key\":\"684f47007ee6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"research\"},\"text\":\"Research overview\"},{\"_key\":\"c868d97c32d2\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"economic-index\"},\"text\":\"Economic Index\"}],\"title\":\"Research\"},{\"_key\":\"4bea354eb2df\",\"links\":[{\"_key\":\"80d38e0df759\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/opus\"},\"text\":\"Claude Opus 4\"},{\"_key\":\"c2b08014bc27\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/sonnet\"},\"text\":\"Claude Sonnet 4\"},{\"_key\":\"45e05dfa0c1f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/haiku\"},\"text\":\"Claude Haiku 3.5\"}],\"title\":\"Claude models\"},{\"_key\":\"d001e7010df1\",\"links\":[{\"_key\":\"85c8ac4fb1e0\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Transparency\",\"url\":\"/transparency\"},{\"_key\":\"15bb62f83096\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Responsible scaling policy\",\"url\":\"/responsible-scaling-policy\"},{\"_key\":\"5a0631335a1d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com\"}],\"title\":\"Commitments\"},{\"_key\":\"9c4341ca2239\",\"links\":[{\"_key\":\"2901ee2ca831\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"AI agents\",\"url\":\"/solutions/agents\"},{\"_key\":\"64ecc4dc6fa6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Coding\",\"url\":\"/solutions/coding\"},{\"_key\":\"88e34e03ea95\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Customer support\",\"url\":\"/solutions/customer-support\"},{\"_key\":\"670f36e1878f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Education\",\"url\":\"/solutions/education\"},{\"_key\":\"b378f665073f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Financial services\",\"url\":\"/solutions/financial-services\"}],\"title\":\"Solutions\"},{\"_key\":\"c5ce914379f2\",\"links\":[{\"_key\":\"fcc415654f97\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"_key\":\"7561dd6ee3bf\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"customers\"},\"text\":\"Customer stories\"},{\"_key\":\"005db6f72186\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"engineering\"},\"text\":\"Engineering at Anthropic\"},{\"_key\":\"3d83335e546e\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"MCP Integrations\",\"url\":\"https://www.anthropic.com/partners/mcp\"},{\"_key\":\"9477fdc66b8f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Partner Directory\",\"url\":\"/partners/powered-by-claude\"}],\"title\":\"Learn\"},{\"_key\":\"fe302c615f58\",\"links\":[{\"_key\":\"6cec00635368\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"About us\",\"url\":\"/company\"},{\"_key\":\"ac4c8a9bb710\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Become a partner\",\"url\":\"https://www.anthropic.com/referral\"},{\"_key\":\"672a82a11105\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Careers\",\"url\":\"/careers\"},{\"_key\":\"91f471f70ecf\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Events\",\"url\":\"/events\"},{\"_key\":\"7508d0e85be1\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"news\"},\"text\":\"News\"},{\"_key\":\"c1fb1a977ea5\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Startups program\",\"url\":\"https://www.anthropic.com/startups\"}],\"title\":\"Explore\"},{\"_key\":\"0cd9ca32ddc4\",\"links\":[{\"_key\":\"24af9e9bd295\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"_key\":\"367db330b179\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Availability\",\"url\":\"/supported-countries\"},{\"_key\":\"c04cac7ae925\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Support center\",\"url\":\"https://support.anthropic.com\"}],\"title\":\"Help and security\"},{\"_key\":\"43371d9865cf\",\"links\":[{\"_key\":\"09f32ce2569b\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Privacy choices\",\"url\":\"#\"},{\"_key\":\"8fd2735bc078\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Privacy policy\",\"url\":\"/legal/privacy\"},{\"_key\":\"151f2d4d7431\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"responsible-disclosure-policy\"},\"text\":\"Responsible disclosure policy\"},{\"_key\":\"51fecf5e2bc6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Terms of service - consumer\",\"url\":\"/legal/consumer-terms\"},{\"_key\":\"4ffd7acc054e\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Terms of service - commercial\",\"url\":\"/legal/commercial-terms\"},{\"_key\":\"b5821a03666a\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Usage policy\",\"url\":\"/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerLinks\":[{\"_key\":\"f3c804963853\",\"card\":{\"backgroundColor\":\"clay\",\"category\":\"News\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/b51062b617d3533149f3ff6fb2fb4a7be06b40db-202x202.svg\",\"width\":202},\"title\":\"Claude's Character\",\"url\":\"https://www.anthropic.com/news/claude-character\"},\"category\":\"Claude\",\"ctas\":[{\"_key\":\"bbe05ac2ec2d\",\"_type\":\"link\",\"text\":\"Download apps\",\"url\":\"https://claude.ai/download\"},{\"_key\":\"e694e1f56596\",\"_type\":\"link\",\"text\":\"Claude log in\",\"url\":\"https://claude.ai\"}],\"sections\":[{\"_key\":\"9be872e8c088\",\"ctas\":null,\"links\":[{\"_key\":\"7b9e2e1a920e\",\"_type\":\"link\",\"page\":null,\"text\":\"Overview\",\"url\":\"/claude\"},{\"_key\":\"c50614051409fd4e967a52a2fb01ed54\",\"_type\":\"link\",\"page\":null,\"text\":\"Max plan\",\"url\":\"/max\"},{\"_key\":\"87d96a948c27\",\"_type\":\"link\",\"page\":null,\"text\":\"Team plan\",\"url\":\"/team\"},{\"_key\":\"c7eb78d4a76c\",\"_type\":\"link\",\"page\":null,\"text\":\"Enterprise plan\",\"url\":\"/enterprise\"},{\"_key\":\"652005e6064e\",\"_type\":\"link\",\"page\":null,\"text\":\"Explore pricing\",\"url\":\"/pricing\"}],\"title\":\"Chat with Claude\"}]},{\"_key\":\"e08b40902cbb\",\"card\":{\"backgroundColor\":\"sky\",\"category\":\"Get started\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/3ba56e79baf0f554c4eefd9e7b2b03388b4c71f2-202x202.svg\",\"width\":202},\"title\":\"Learn how to build with Claude\",\"url\":\"https://docs.anthropic.com/en/docs/welcome\"},\"category\":\"API\",\"ctas\":[{\"_key\":\"951245c80d71\",\"_type\":\"link\",\"text\":\"Console log in\",\"url\":\"https://console.anthropic.com\"}],\"sections\":[{\"_key\":\"f5435c9757d4\",\"ctas\":null,\"links\":[{\"_key\":\"1d805e0b2516\",\"_type\":\"link\",\"page\":null,\"text\":\"API overview\",\"url\":\"/api\"},{\"_key\":\"48bd8d8dc982\",\"_type\":\"link\",\"page\":null,\"text\":\"Developer docs\",\"url\":\"https://docs.anthropic.com\"},{\"_key\":\"9667b32966f8\",\"_type\":\"link\",\"page\":null,\"text\":\"Explore pricing\",\"url\":\"/pricing#api\"}],\"title\":\"Build with Claude\"}]},{\"_key\":\"5ee6c9e8bb40\",\"card\":{\"backgroundColor\":\"heather\",\"category\":\"Case studies\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/979f7ac1f86e96870f547a788de6edce2e79f8ce-202x202.svg\",\"width\":202},\"title\":\"Hear from our customers\",\"url\":\"/customers\"},\"category\":\"Solutions\",\"sections\":[{\"_key\":\"86c91f34e78e\",\"ctas\":null,\"links\":[{\"_key\":\"ef97aea86c51\",\"_type\":\"link\",\"page\":null,\"text\":\"AI agents\",\"url\":\"/solutions/agents\"},{\"_key\":\"4601f5837a58\",\"_type\":\"link\",\"page\":null,\"text\":\"Coding\",\"url\":\"/solutions/coding\"},{\"_key\":\"9d8be85830aa\",\"_type\":\"link\",\"page\":null,\"text\":\"Customer support\",\"url\":\"/solutions/customer-support\"},{\"_key\":\"452aad7468f3\",\"_type\":\"link\",\"page\":null,\"text\":\"Education\",\"url\":\"/solutions/education\"},{\"_key\":\"987465dada46\",\"_type\":\"link\",\"page\":null,\"text\":\"Financial services\",\"url\":\"https://www.anthropic.com/solutions/financial-services\"}],\"title\":\"Collaborate with Claude\"}]},{\"_key\":\"be5d4ecfc005\",\"card\":{\"backgroundColor\":\"olive\",\"category\":\"Research\",\"illustration\":{\"description\":null,\"height\":205,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/057a57864dc1d2f7e6639a02f65ea77f08a19095-206x205.svg\",\"width\":206},\"title\":\"Claude’s extended thinking\",\"url\":\"https://www.anthropic.com/news/visible-extended-thinking\"},\"category\":\"Research\",\"sections\":[{\"_key\":\"cad375af37cc\",\"ctas\":null,\"links\":[{\"_key\":\"8782be9dc2e6\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-03-09T15:23:03Z\",\"_id\":\"b5e6b6d0-f668-4312-8a00-0e804343be62\",\"_rev\":\"8Ka5T868moynofPrGLUbQN\",\"_type\":\"page\",\"_updatedAt\":\"2024-06-20T14:51:58Z\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"19e3de5eb45a\",\"_ref\":\"fe5e453b-ae1a-431c-bea8-e54463427acf\",\"_type\":\"reference\"},{\"_key\":\"3eae5ef11e92\",\"_ref\":\"a50d379e-8adc-4ed2-9e76-d7235165cb25\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"research\"},\"title\":\"Research\"},\"text\":\"Overview\"},{\"_key\":\"2c08fec00aed\",\"_type\":\"link\",\"page\":null,\"text\":\"Economic Index\",\"url\":\"/economic-index\"}],\"title\":\"Research\"},{\"_key\":\"6efa8c7f7494\",\"ctas\":null,\"links\":[{\"_key\":\"818055e9fe1f\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2025-04-21T17:05:10Z\",\"_id\":\"b8764a5f-abd4-4309-99c5-e01e3ff51522\",\"_rev\":\"v1N2wBpLqoO2Q3HXueXvWh\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:05Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-fddc15df8b1165f09cd04d1f058ebf2fefdce044-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"c331074239a6\",\"_ref\":\"a34e7f7e-46f2-484f-b062-32731331e9b8\",\"_type\":\"reference\"},{\"_key\":\"9faf70e8babd\",\"_ref\":\"9c03dad9-7467-4b6e-8023-7d26aaa74ba5\",\"_type\":\"reference\"},{\"_key\":\"f8b0f6cdff5f\",\"_ref\":\"e2ca4bc4-7deb-4c63-90ce-6133e0e79485\",\"_type\":\"reference\"},{\"_key\":\"d4095061a27a\",\"_ref\":\"5a00b439-1474-430a-89ec-770fcbaba807\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/opus\"},\"title\":\"Claude Opus 4\"},\"text\":\"Claude Opus 4\"},{\"_key\":\"694bd6fd50da\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-09-25T13:40:13Z\",\"_id\":\"708a028d-58f2-4980-9a7c-a99523d8131f\",\"_rev\":\"6i7QQZ2OJnE58VEiPrJJZm\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:06Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-671633efbf2333613d6c37b73cb55e82cf52a531-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"efbca8873737\",\"_ref\":\"28727556-38a3-4a03-acbd-008f6d089de7\",\"_type\":\"reference\"},{\"_key\":\"23581c5e08d5\",\"_ref\":\"57b4e21b-6c38-4acc-8f1a-9e8ea518f76f\",\"_type\":\"reference\"},{\"_key\":\"f80cd327fa56\",\"_ref\":\"eb888530-a73b-4edc-9a84-dd16cadb8ee3\",\"_type\":\"reference\"},{\"_key\":\"6dd0528e1a73\",\"_ref\":\"5fe75448-6894-4e2c-ac2a-f5a24095b63a\",\"_type\":\"reference\"},{\"_key\":\"910bd8f316b6\",\"_ref\":\"e32cfcea-219c-42f4-8b1c-1ed0122ff768\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/sonnet\"},\"title\":\"Claude Sonnet 4\"},\"text\":\"Claude Sonnet 4\"},{\"_key\":\"0f9e98ccca5d\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-10-09T10:02:31Z\",\"_id\":\"1e71d541-7a84-444f-85e5-c316b148356e\",\"_rev\":\"3YEDAdif46o4m1ICOQXYPz\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:03Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-597723b70ccbe694ff3788144b3be87b9ce1536c-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"efbca8873737\",\"_ref\":\"46bd14aa-e4b3-435f-b3d8-2e4e63b32fda\",\"_type\":\"reference\"},{\"_key\":\"dfe0dacb58af\",\"_ref\":\"ae5d1645-49b9-422a-860f-2ba6e89afb8e\",\"_type\":\"reference\"},{\"_key\":\"5d9ed9fb4557\",\"_ref\":\"8f48e72e-488b-45a5-acf3-395ec7d644db\",\"_type\":\"reference\"},{\"_key\":\"57f111c726cf\",\"_ref\":\"6b9e22f8-135d-4e21-95c9-9bca6646fadf\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/haiku\"},\"title\":\"Claude Haiku 3.5\"},\"text\":\"Claude Haiku 3.5\"}],\"title\":\"Claude model family\"}]},{\"_key\":\"b01af56fae81\",\"card\":{\"backgroundColor\":\"fig\",\"category\":\"Announcements\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/9caa14b490b0f02f7b3e5a37e6ea171f182a2544-202x202.svg\",\"width\":202},\"title\":\"ISO 42001 certification\",\"url\":\"/news/anthropic-achieves-iso-42001-certification-for-responsible-ai\"},\"category\":\"Commitments\",\"sections\":[{\"_key\":\"ae13eec166b3\",\"ctas\":null,\"links\":[{\"_key\":\"f1bf2286ea51\",\"_type\":\"link\",\"page\":null,\"text\":\"Transparency\",\"url\":\"/transparency\"},{\"_key\":\"0da6e18eb7d0\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-10-14T14:08:37Z\",\"_id\":\"19367d7a-f3f5-4316-b356-fd9fc6fcce46\",\"_rev\":\"7NkZcZZTh11FSYYzVK1kZK\",\"_type\":\"post\",\"_updatedAt\":\"2024-10-15T20:44:11Z\",\"body\":[{\"_key\":\"177824ba8e58\",\"_type\":\"block\",\"children\":[{\"_key\":\"b66b73206ce30\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. \"},{\"_key\":\"b66b73206ce31\",\"_type\":\"span\",\"marks\":[],\"text\":\"This update introduces a more flexible and nuanced approach to assessing and managing AI risks while maintaining our commitment not to train or deploy models unless we have implemented adequate safeguards. Key improvements include new capability thresholds to indicate when we will upgrade our safeguards, refined processes for evaluating model capabilities and the adequacy of our safeguards (inspired by \"},{\"_key\":\"b66b73206ce32\",\"_type\":\"span\",\"marks\":[\"a8d027e86aae\"],\"text\":\"safety case methodologies\"},{\"_key\":\"b66b73206ce33\",\"_type\":\"span\",\"marks\":[],\"text\":\"), and new measures for internal governance and external input. By learning from our implementation experiences and drawing on risk management practices used in other high-consequence industries, we aim to better prepare for the rapid pace of AI advancement.\"}],\"markDefs\":[{\"_key\":\"a8d027e86aae\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2403.10462\"}],\"style\":\"normal\"},{\"_key\":\"1c3077afa1f5\",\"_type\":\"block\",\"children\":[{\"_key\":\"9405114da2700\",\"_type\":\"span\",\"marks\":[],\"text\":\"The promise and challenge of advanced AI\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"750223c4acfb\",\"_type\":\"block\",\"children\":[{\"_key\":\"a1dcb0091c340\",\"_type\":\"span\",\"marks\":[],\"text\":\"As frontier AI models advance, they have the potential to bring about transformative benefits for our society and economy. AI could accelerate scientific discoveries, revolutionize healthcare, enhance our education system, and create entirely new domains for human creativity and innovation. However, frontier AI systems also present new challenges and risks that warrant careful study and effective safeguards.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c8b393e2960c\",\"_type\":\"block\",\"children\":[{\"_key\":\"b75aa93fa2c80\",\"_type\":\"span\",\"marks\":[],\"text\":\"In September 2023, we \"},{\"_key\":\"b75aa93fa2c81\",\"_type\":\"span\",\"marks\":[\"4791430b5ec2\"],\"text\":\"released\"},{\"_key\":\"b75aa93fa2c82\",\"_type\":\"span\",\"marks\":[],\"text\":\" our Responsible Scaling Policy, a framework for managing risks from increasingly capable AI systems. After a year of implementation and learning, we are now sharing a significantly updated version that reflects practical insights and accounts for advancing technological capabilities.\"}],\"markDefs\":[{\"_key\":\"4791430b5ec2\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/news/anthropics-responsible-scaling-policy\"}],\"style\":\"normal\"},{\"_key\":\"a1948e4cc873\",\"_type\":\"block\",\"children\":[{\"_key\":\"5d488fbe87cd0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Although this policy focuses on catastrophic risks like the categories listed below, they are not the only risks that we monitor and prepare for. Our \"},{\"_key\":\"5d488fbe87cd1\",\"_type\":\"span\",\"marks\":[\"ba04e1121891\"],\"text\":\"Usage Policy\"},{\"_key\":\"5d488fbe87cd2\",\"_type\":\"span\",\"marks\":[],\"text\":\" sets forth our standards for the use of our products, including rules that prohibit using our models to spread misinformation, incite violence or hateful behavior, or engage in fraudulent or abusive practices. We continually refine our technical measures for enforcing our trust and safety standards at scale. Further, we conduct research to understand the broader \"},{\"_key\":\"5d488fbe87cd3\",\"_type\":\"span\",\"marks\":[\"32798753cd99\"],\"text\":\"societal impacts\"},{\"_key\":\"5d488fbe87cd4\",\"_type\":\"span\",\"marks\":[],\"text\":\" of our models. Our Responsible Scaling Policy complements our work in these areas, contributing to our understanding of current and potential risks.\"}],\"markDefs\":[{\"_key\":\"ba04e1121891\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/legal/aup\"},{\"_key\":\"32798753cd99\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research#societal-impacts\"}],\"style\":\"normal\"},{\"_key\":\"3b55c0bceff9\",\"_type\":\"block\",\"children\":[{\"_key\":\"5525570b2a010\",\"_type\":\"span\",\"marks\":[],\"text\":\"A framework for proportional safeguards\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"ad1d58dbdd5b\",\"_type\":\"block\",\"children\":[{\"_key\":\"cdd8f6a2997b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"As before, we maintain our core commitment: we will not train or deploy models unless we have implemented safety and security measures that keep risks below acceptable levels. Our RSP is based on the principle of proportional protection: safeguards that scale with potential risks. To do this, we use \"},{\"_key\":\"3517fb380020\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"AI Safety Level Standards (ASL Standards)\"},{\"_key\":\"aede15153eee\",\"_type\":\"span\",\"marks\":[],\"text\":\", graduated sets of safety and security measures that become more stringent as model capabilities increase. Inspired by \"},{\"_key\":\"cdd8f6a2997b1\",\"_type\":\"span\",\"marks\":[\"f8e6f3368061\"],\"text\":\"Biosafety Levels,\"},{\"_key\":\"cdd8f6a2997b2\",\"_type\":\"span\",\"marks\":[],\"text\":\" these begin at ASL-1 for models that have very basic capabilities (for example, chess-playing bots) and progress through ASL-2, ASL-3, and so on.\"}],\"markDefs\":[{\"_key\":\"f8e6f3368061\",\"_type\":\"link\",\"href\":\"https://en.wikipedia.org/wiki/Biosafety_level\"}],\"style\":\"normal\"},{\"_key\":\"18e2a21a8d24\",\"_type\":\"block\",\"children\":[{\"_key\":\"94961b6308040\",\"_type\":\"span\",\"marks\":[],\"text\":\"In our updated policy, we have refined our methodology for assessing specific capabilities (and their associated risks) and implementing proportional safety and security measures. Our updated framework has two key components:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"110d48e0214c\",\"_type\":\"block\",\"children\":[{\"_key\":\"4fa1b51cfc900\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Capability Thresholds:\"},{\"_key\":\"f90398ece8b9\",\"_type\":\"span\",\"marks\":[],\"text\":\" Specific AI abilities that, if reached, would require stronger safeguards than our current baseline.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"132d0001c926\",\"_type\":\"block\",\"children\":[{\"_key\":\"d0053cd57ea60\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Required Safeguards: \"},{\"_key\":\"663a30c5e5b1\",\"_type\":\"span\",\"marks\":[],\"text\":\"The specific ASL Standards needed to mitigate risks once a Capability Threshold has been reached.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"36479c291519\",\"_type\":\"block\",\"children\":[{\"_key\":\"a03bfcd2c90a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"At present, all of our models operate under ASL-2 Standards, which reflect current industry best practices. Our updated policy defines two key Capability Thresholds that would require upgraded safeguards:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"7960a2e610b8\",\"_type\":\"block\",\"children\":[{\"_key\":\"113a03232f950\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Autonomous AI Research and Development:\"},{\"_key\":\"559bae44e291\",\"_type\":\"span\",\"marks\":[],\"text\":\" If a model can independently conduct complex AI research tasks typically requiring human expertise—potentially significantly accelerating AI development in an unpredictable way—we require elevated security standards (potentially ASL-4 or higher standards) and additional safety assurances to avoid a situation where development outpaces our ability to address emerging risks.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b1e7e0200f28\",\"_type\":\"block\",\"children\":[{\"_key\":\"04f8008234340\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Chemical, Biological, Radiological, and Nuclear (CBRN) weapons:\"},{\"_key\":\"e87c145d832e\",\"_type\":\"span\",\"marks\":[],\"text\":\" If a model can meaningfully assist someone with a basic technical background in creating or deploying CBRN weapons, we require enhanced security and deployment safeguards (ASL-3 standards).\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5028d8139378\",\"_type\":\"block\",\"children\":[{\"_key\":\"c21521b5c8660\",\"_type\":\"span\",\"marks\":[],\"text\":\"ASL-3 safeguards involve enhanced security measures and deployment controls. On the security side, this will include internal access controls and more robust protection of model weights. For deployment risks, we plan to implement a multi-layered approach to prevent misuse, including real-time and asynchronous monitoring, rapid response protocols, and thorough pre-deployment red teaming.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9d149ea1669f\",\"_type\":\"block\",\"children\":[{\"_key\":\"c9476c97d6320\",\"_type\":\"span\",\"marks\":[],\"text\":\"Implementation and oversight\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"081edde580ae\",\"_type\":\"block\",\"children\":[{\"_key\":\"0898891e3fd00\",\"_type\":\"span\",\"marks\":[],\"text\":\"To contribute to effective implementation of the policy, we have established:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1ef822ef2fa2\",\"_type\":\"block\",\"children\":[{\"_key\":\"65ad635ebc020\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Capability assessments\"},{\"_key\":\"ee8bb23f5481\",\"_type\":\"span\",\"marks\":[],\"text\":\": Routine model evaluations based on our Capability Thresholds to determine whether our current safeguards are still appropriate. (Summaries of past assessments are available \"},{\"_key\":\"65ad635ebc021\",\"_type\":\"span\",\"marks\":[\"e97965203d94\"],\"text\":\"here\"},{\"_key\":\"65ad635ebc022\",\"_type\":\"span\",\"marks\":[],\"text\":\".)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"e97965203d94\",\"_type\":\"link\",\"href\":\"http://www.anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"b5fc19b935bb\",\"_type\":\"block\",\"children\":[{\"_key\":\"fd96692cf5950\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Safeguard assessments: \"},{\"_key\":\"bbdf4a0ded13\",\"_type\":\"span\",\"marks\":[],\"text\":\"Routine evaluation of the effectiveness of our security and deployment safety measures to assess whether we have met the Required Safeguards bar. (Summaries of these decisions will be available \"},{\"_key\":\"fd96692cf5951\",\"_type\":\"span\",\"marks\":[\"d6b74c71ad6d\"],\"text\":\"here\"},{\"_key\":\"fd96692cf5952\",\"_type\":\"span\",\"marks\":[],\"text\":\".)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"d6b74c71ad6d\",\"_type\":\"link\",\"href\":\"http://www.anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"8074ca752c13\",\"_type\":\"block\",\"children\":[{\"_key\":\"ed8d6ec6368a0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Documentation and decision-making: \"},{\"_key\":\"d451a32ef6cb\",\"_type\":\"span\",\"marks\":[],\"text\":\"Processes for documenting the capability and safeguard assessments, inspired by procedures (such as \"},{\"_key\":\"ed8d6ec6368a1\",\"_type\":\"span\",\"marks\":[\"dd97b493d101\"],\"text\":\"safety case methodologies\"},{\"_key\":\"ed8d6ec6368a2\",\"_type\":\"span\",\"marks\":[],\"text\":\") common in high-reliability industries.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"dd97b493d101\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2403.10462\"}],\"style\":\"normal\"},{\"_key\":\"60c9b7dabd40\",\"_type\":\"block\",\"children\":[{\"_key\":\"ca95d473f4a90\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Measures for internal governance and external input: \"},{\"_key\":\"fb68635efd29\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our assessment methodology will be backed up by internal stress-testing in addition to our existing internal reporting process for safety issues. We are also soliciting external expert feedback on our methodologies.\"},{\"_key\":\"7ddd60e07d17\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"1\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6e5effe0bac6\",\"_type\":\"block\",\"children\":[{\"_key\":\"ecdac5e44ed40\",\"_type\":\"span\",\"marks\":[],\"text\":\"Learning from experience\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"142037ff4afb\",\"_type\":\"block\",\"children\":[{\"_key\":\"8932eeee77830\",\"_type\":\"span\",\"marks\":[],\"text\":\"We have learned a lot in our first year with the previous RSP in effect, and are using this update as an opportunity to reflect on what has worked well and what makes sense to update in the policy. As part of this, we conducted our first review of how well we adhered to the framework and identified a small number of instances where we fell short of meeting the full letter of its requirements. These included procedural issues such as completing a set of evaluations three days later than scheduled or a lack of clarity on how and where we should note any changes to our placeholder evaluations. We also flagged some evaluations where we may have been able to elicit slightly better model performance through implementing standard techniques (such as chain-of-thought or best-of-N).\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fdd39c742e14\",\"_type\":\"block\",\"children\":[{\"_key\":\"2c9de8a77cf10\",\"_type\":\"span\",\"marks\":[],\"text\":\"In all cases, we found these instances posed minimal risk to the safety of our models. We used the additional three days to refine and improve our evaluations; the different set of evaluations we used provided a more accurate assessment than the placeholder evaluations; and our evaluation methodology still showed we were sufficiently far from the thresholds. From this, we learned two valuable lessons to incorporate into our updated framework: we needed to incorporate more flexibility into our policies, and we needed to improve our process for tracking compliance with the RSP. You can read more \"},{\"_key\":\"2c9de8a77cf11\",\"_type\":\"span\",\"marks\":[\"724c1bcc37c6\"],\"text\":\"here\"},{\"_key\":\"2c9de8a77cf12\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"724c1bcc37c6\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"c84e70ee115b\",\"_type\":\"block\",\"children\":[{\"_key\":\"855d60a456920\",\"_type\":\"span\",\"marks\":[],\"text\":\"Since we first released the RSP a year ago, our goal has been to offer an example of a framework that others might draw inspiration from when crafting their own AI risk governance policies. We hope that proactively sharing our experiences implementing our own policy will help other companies in implementing their own risk management frameworks and contribute to the establishment of best practices across the AI ecosystem.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"20a9139b3a51\",\"_type\":\"block\",\"children\":[{\"_key\":\"81a081f760a10\",\"_type\":\"span\",\"marks\":[],\"text\":\"Looking ahead\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"78baf5750bd0\",\"_type\":\"block\",\"children\":[{\"_key\":\"252e5f0060c50\",\"_type\":\"span\",\"marks\":[],\"text\":\"The frontier of AI is advancing rapidly, making it challenging to anticipate what safety measures will be appropriate for future systems. All aspects of our safety program will continue to evolve: our policies, evaluation methodology, safeguards, and our research into potential risks and mitigations.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2afadf824368\",\"_type\":\"block\",\"children\":[{\"_key\":\"744b6d45ddff0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Additionally, Co-Founder and Chief Science Officer Jared Kaplan will serve as Anthropic’s Responsible Scaling Officer, succeeding Co-Founder and Chief Technology Officer Sam McCandlish who held this role over the last year. Sam oversaw the RSP’s initial implementation and will continue to focus on his duties as Chief Technology Officer. As we work to scale up our efforts on implementing the RSP, we’re also opening a position for a Head of Responsible Scaling. This role will be responsible for coordinating the many teams needed to iterate on and successfully comply with the RSP.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"88e4ecab085f\",\"_type\":\"block\",\"children\":[{\"_key\":\"d603f352b2580\",\"_type\":\"span\",\"marks\":[],\"text\":\"If you would like to contribute to AI risk management at Anthropic, \"},{\"_key\":\"d0297560aab0\",\"_type\":\"span\",\"marks\":[\"6210958b799c\"],\"text\":\"we are hiring\"},{\"_key\":\"ec2a1674bc0a\",\"_type\":\"span\",\"marks\":[],\"text\":\"! Many of our teams now contribute to risk management via the RSP, including:\"}],\"markDefs\":[{\"_key\":\"6210958b799c\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/jobs\"}],\"style\":\"normal\"},{\"_key\":\"803749c5db22\",\"_type\":\"block\",\"children\":[{\"_key\":\"0a4d9f27a0cd0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Frontier Red Team (responsible for threat modeling and capability assessments)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fe760029da3a\",\"_type\":\"block\",\"children\":[{\"_key\":\"dc5557c893ca0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Trust \u0026 Safety (responsible for developing deployment safeguards)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"97772c2e43a6\",\"_type\":\"block\",\"children\":[{\"_key\":\"b2222f32b3830\",\"_type\":\"span\",\"marks\":[],\"text\":\"Security and Compliance (responsible for security safeguards and risk management)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"bed9fc27e95a\",\"_type\":\"block\",\"children\":[{\"_key\":\"32cf53008a870\",\"_type\":\"span\",\"marks\":[],\"text\":\"Alignment Science (including sub-teams responsible for developing ASL-3+ safety measures, for misalignment-focused capability evaluations, and for our internal alignment stress-testing program)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ddb2b97916b4\",\"_type\":\"block\",\"children\":[{\"_key\":\"5dd36bc76b200\",\"_type\":\"span\",\"marks\":[],\"text\":\"RSP Team (responsible for policy drafting, assurance, and cross-company execution)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"82e7288c8b9b\",\"_type\":\"block\",\"children\":[{\"_key\":\"ff739d8fa1fb0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Read the updated policy at \"},{\"_key\":\"ff739d8fa1fb1\",\"_type\":\"span\",\"marks\":[\"64573f7728d5\",\"strong\"],\"text\":\"anthropic.com/rsp\"},{\"_key\":\"ff739d8fa1fb2\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\", and supplementary information at \"},{\"_key\":\"ff739d8fa1fb3\",\"_type\":\"span\",\"marks\":[\"0b409c03c219\",\"strong\"],\"text\":\"anthropic.com/rsp-updates\"},{\"_key\":\"f2c90e528143\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"64573f7728d5\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp\"},{\"_key\":\"0b409c03c219\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"4730ec071c8d\",\"_type\":\"block\",\"children\":[{\"_key\":\"f524c11dc591\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"We extend our sincere gratitude to the many external groups that provided invaluable feedback on the development and refinement of our Responsible Scaling Policy.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"df20b8535b76\",\"_type\":\"block\",\"children\":[{\"_key\":\"3c4f171f7b070\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\n\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5995bb58cadf\",\"_type\":\"block\",\"children\":[{\"_key\":\"8bcb9103a3e80\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6d34bef42728\",\"_type\":\"block\",\"children\":[{\"_key\":\"3a62da5cab740\",\"_type\":\"span\",\"marks\":[],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"}],\"cardPhoto\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-591404bad10f6fb79c2561d72999e30d633792f2-1312x1312-png\",\"_type\":\"reference\"},\"description\":\"A hand with a feather quill writing a policy document. \"},\"cta\":{\"_type\":\"link\",\"text\":\"Read the Responsible Scaling Policy \",\"url\":\"http://anthropic.com/rsp \"},\"directories\":[{\"_key\":\"news\",\"_type\":\"tag\",\"label\":\"News\",\"value\":\"news\"}],\"fileAsset\":null,\"footnotesBody\":[{\"_key\":\"0de7792a2f97\",\"_type\":\"block\",\"children\":[{\"_key\":\"becd184f796c\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"1\"},{\"_key\":\"1aba967f3e65\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"4061449d7e34\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"We have also shared our assessment methodology with both AI Safety Institutes, as well as a selection of independent experts and organizations, for feedback. This does not represent an endorsement from either AI Safety Institute or the independent experts and organizations. \"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e012dfcd0680\",\"_type\":\"block\",\"children\":[{\"_key\":\"a5a0fc3d405c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\n\"}],\"markDefs\":[],\"style\":\"normal\"}],\"footnotesTitle\":\"Footnotes\",\"hero\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-f1664b95be4e2e828a180cf9f015a0b6f8365472-5760x3240-png\",\"_type\":\"reference\"},\"description\":\"A hand with a feather quill writing a policy document. \"},\"hideCardPhotos\":true,\"meta\":{\"robotsIndexable\":true,\"seoDescription\":\"Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. \",\"seoTitle\":\"Announcing our updated Responsible Scaling Policy\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-4048dcbe1e4e38c32891bfb7ca28c1b7628982cd-2400x1260-png\",\"_type\":\"reference\"},\"description\":\"A hand writing on a policy document with a feathered quill.\"}},\"modalId\":null,\"page\":null,\"publishedOn\":\"2024-10-15T13:30:00.000Z\",\"relatedLinksLabel\":\"Related\",\"slug\":{\"_type\":\"slug\",\"current\":\"announcing-our-updated-responsible-scaling-policy\"},\"subjects\":[{\"_key\":\"announcements\",\"_type\":\"tag\",\"label\":\"Announcements\",\"value\":\"announcements\"}],\"title\":\"Announcing our updated Responsible Scaling Policy\"},\"text\":\"Responsible scaling policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"560566d26fd7\",\"ctas\":null,\"links\":[{\"_key\":\"dbaa54335108\",\"_type\":\"link\",\"page\":null,\"text\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com\"}],\"title\":\"Trust center\"}]},{\"_key\":\"cd1c8470153f\",\"card\":{\"backgroundColor\":\"cactus\",\"category\":\"Engineering\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/ba1df32e7763906f03faafe0296daa48582e33f1-202x202.svg\",\"width\":202},\"title\":\"Building effective agents\",\"url\":\"/engineering/building-effective-agents\"},\"category\":\"Learn\",\"sections\":[{\"_key\":\"7a719b73abbb\",\"ctas\":null,\"links\":[{\"_key\":\"007e6aabc528\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-01-30T00:11:55Z\",\"_id\":\"e2db4c62-abf9-4a1c-9a98-5ff2b79f2320\",\"_rev\":\"uw6aKX3p7ldDBUNqIn6RAI\",\"_system\":{\"base\":{\"id\":\"e2db4c62-abf9-4a1c-9a98-5ff2b79f2320\",\"rev\":\"e1SehYHuBOmzIsNebUGsLA\"}},\"_type\":\"page\",\"_updatedAt\":\"2025-06-24T21:09:08Z\",\"backgroundColor\":\"ivory-light\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"88aa1cc7438d\",\"_ref\":\"9ceeaa12-216b-451f-936d-148ae89bd9a4\",\"_type\":\"reference\"},{\"_key\":\"fd2e4c8f9cf9\",\"_ref\":\"9acb1a29-a11f-4bf3-9b48-34e84f719f4c\",\"_type\":\"reference\"}],\"showParentBreadcrumb\":false,\"slug\":{\"_type\":\"slug\",\"current\":\"customers\"},\"title\":\"Customers\"},\"text\":\"Customer stories\"},{\"_key\":\"31bccebee35f\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2025-01-15T15:45:48Z\",\"_id\":\"8eaf3767-6721-42f3-859e-a543f19d47ce\",\"_rev\":\"3R9N6zTx1UJr6GwDEwhCSk\",\"_type\":\"page\",\"_updatedAt\":\"2025-01-24T13:34:54Z\",\"backgroundColor\":\"default\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"meta\":{\"robotsIndexable\":true},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"3d5239c1764e\",\"_ref\":\"e17da550-f3b8-4db6-9468-450735111295\",\"_type\":\"reference\"},{\"_key\":\"db37cd406356\",\"_ref\":\"2e2c486e-e54f-4f6f-afa9-a2ccbb2ff50e\",\"_type\":\"reference\"},{\"_key\":\"80c405b7b714\",\"_ref\":\"2c96ba24-d412-474a-8a42-32313c274e68\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"engineering\"},\"title\":\"Engineering\"},\"text\":\"Engineering at Anthropic\"},{\"_key\":\"e84dc24f1ec9\",\"_type\":\"link\",\"page\":null,\"text\":\"Anthropic Academy\",\"url\":\"/learn\"}],\"title\":\"Learning resources\"},{\"_key\":\"c2bbb3e1ab9e\",\"ctas\":null,\"links\":[{\"_key\":\"1752279b09b4\",\"_type\":\"link\",\"page\":null,\"text\":\"About\",\"url\":\"/company\"},{\"_key\":\"64be129555a4\",\"_type\":\"link\",\"page\":null,\"text\":\"Careers\",\"url\":\"/careers\"},{\"_key\":\"16942f1cf8cd\",\"_type\":\"link\",\"page\":null,\"text\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"e5092f7e4cbe\",\"card\":{\"backgroundColor\":\"default\",\"illustration\":{\"description\":null,\"height\":218,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/9f1bfa202fd78bc4743325ee8199cf18522bb4e7-232x218.svg\",\"width\":232}},\"category\":\"News\",\"sections\":[{\"_key\":\"fc4a00e73c8e\",\"ctas\":null,\"links\":[{\"_key\":\"86995b085b67\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-06-01T05:13:58Z\",\"_id\":\"65ed983f-1db1-4655-b662-8c7169802ac8\",\"_rev\":\"7NkZcZZTh11FSYYzW6mvR0\",\"_type\":\"page\",\"_updatedAt\":\"2024-10-22T14:59:18Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"9f02fd3a3264\",\"_ref\":\"d0b62aec-4f07-4c1d-a81b-e3886b962d69\",\"_type\":\"reference\"},{\"_key\":\"f0382a77591e\",\"_ref\":\"243ed60e-70f7-4392-a626-2138ef076c18\",\"_type\":\"reference\"}],\"showParentBreadcrumb\":false,\"slug\":{\"_type\":\"slug\",\"current\":\"news\"},\"title\":\"Newsroom\"},\"text\":\"News\"}],\"title\":\"Latest Updates\"}]}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"navCta\":{\"_createdAt\":\"2024-01-12T17:43:21Z\",\"_id\":\"25aac41e-7435-47df-b392-6ea22f2abf0b\",\"_rev\":\"1oQP6cQFlFaIeBWKVicLJ3\",\"_type\":\"link\",\"_updatedAt\":\"2024-06-25T14:41:03Z\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/amazon-bedrock\",\"/api\",\"/app-unavailable-in-region\",\"/campus\",\"/careers\",\"/claude\",\"/claude-code\",\"/claude-in-slack\",\"/claude-in-slack/error\",\"/claude-in-slack/installation-disabled\",\"/claude-in-slack/success\",\"/claude-in-slack/upgrade-success\",\"/company\",\"/contact-sales\",\"/enterprise\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/for/parents\",\"/for/students\",\"/for/writers\",\"/google-cloud-vertex-ai\",\"/max\",\"/partners/mcp\",\"/partners/powered-by-claude\",\"/pricing\",\"/solutions/agents\",\"/solutions/coding\",\"/solutions/customer-support\",\"/solutions/education\",\"/solutions/financial-services\",\"/supported-countries\",\"/team\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\"}}]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"1f:[\"$\",\"$L25\",null,{\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"DElaXo1A74rjItEmVcn9bL\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"zaypqwxsSibfVwOwoBcVU7\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2025-07-17T22:34:08Z\",\"announcement\":null,\"copyright\":\"© 2025 Anthropic PBC\",\"footerLinks\":[{\"_key\":\"7299741de33c\",\"links\":[{\"_key\":\"a5082bfd9e4d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude overview\",\"url\":\"/claude\"},{\"_key\":\"a7a819d6de49\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude Code\",\"url\":\"/claude-code\"},{\"_key\":\"4269e8ecebc8409bdb4b05e05bee85b8\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Max plan\",\"url\":\"/max\"},{\"_key\":\"ee78393233bc\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Team plan\",\"url\":\"/team\"},{\"_key\":\"14e1a3c222e9\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Enterprise plan\",\"url\":\"/enterprise\"},{\"_key\":\"7aa63ef4a4aa\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Download Claude apps\",\"url\":\"https://claude.ai/download\"},{\"_key\":\"5459b2c57b97\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude.ai pricing plans\",\"url\":\"/pricing\"},{\"_key\":\"f3fd0e46d1a3\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Claude.ai login\",\"url\":\"http://claude.ai/login\"}],\"title\":\"Product\"},{\"_key\":\"785d9820a620\",\"links\":[{\"_key\":\"44287b42495c\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"API overview\",\"url\":\"/api\"},{\"_key\":\"f062f9193e7d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Developer docs\",\"url\":\"https://docs.anthropic.com/\"},{\"_key\":\"5bd32b4b104f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude in Amazon Bedrock\",\"url\":\"/amazon-bedrock\"},{\"_key\":\"34544a290d87\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Claude on Google Cloud's Vertex AI\",\"url\":\"/google-cloud-vertex-ai\"},{\"_key\":\"40a59f463410\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Pricing\",\"url\":\"/pricing#api\"},{\"_key\":\"4cf4c434288c\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Console login\",\"url\":\"https://console.anthropic.com/\"}],\"title\":\"API Platform\"},{\"_key\":\"2c41834b2ec3\",\"links\":[{\"_key\":\"684f47007ee6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"research\"},\"text\":\"Research overview\"},{\"_key\":\"c868d97c32d2\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"economic-index\"},\"text\":\"Economic Index\"}],\"title\":\"Research\"},{\"_key\":\"4bea354eb2df\",\"links\":[{\"_key\":\"80d38e0df759\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/opus\"},\"text\":\"Claude Opus 4\"},{\"_key\":\"c2b08014bc27\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/sonnet\"},\"text\":\"Claude Sonnet 4\"},{\"_key\":\"45e05dfa0c1f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"claude/haiku\"},\"text\":\"Claude Haiku 3.5\"}],\"title\":\"Claude models\"},{\"_key\":\"d001e7010df1\",\"links\":[{\"_key\":\"85c8ac4fb1e0\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\" Transparency\",\"url\":\"/transparency\"},{\"_key\":\"15bb62f83096\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Responsible scaling policy\",\"url\":\"/responsible-scaling-policy\"},{\"_key\":\"5a0631335a1d\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com\"}],\"title\":\"Commitments\"},{\"_key\":\"9c4341ca2239\",\"links\":[{\"_key\":\"2901ee2ca831\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"AI agents\",\"url\":\"/solutions/agents\"},{\"_key\":\"64ecc4dc6fa6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Coding\",\"url\":\"/solutions/coding\"},{\"_key\":\"88e34e03ea95\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Customer support\",\"url\":\"/solutions/customer-support\"},{\"_key\":\"670f36e1878f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Education\",\"url\":\"/solutions/education\"},{\"_key\":\"b378f665073f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Financial services\",\"url\":\"/solutions/financial-services\"}],\"title\":\"Solutions\"},{\"_key\":\"c5ce914379f2\",\"links\":[{\"_key\":\"fcc415654f97\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"_key\":\"7561dd6ee3bf\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"customers\"},\"text\":\"Customer stories\"},{\"_key\":\"005db6f72186\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"engineering\"},\"text\":\"Engineering at Anthropic\"},{\"_key\":\"3d83335e546e\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"MCP Integrations\",\"url\":\"https://www.anthropic.com/partners/mcp\"},{\"_key\":\"9477fdc66b8f\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Partner Directory\",\"url\":\"/partners/powered-by-claude\"}],\"title\":\"Learn\"},{\"_key\":\"fe302c615f58\",\"links\":[{\"_key\":\"6cec00635368\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"About us\",\"url\":\"/company\"},{\"_key\":\"ac4c8a9bb710\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Become a partner\",\"url\":\"https://www.anthropic.com/referral\"},{\"_key\":\"672a82a11105\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Careers\",\"url\":\"/careers\"},{\"_key\":\"91f471f70ecf\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Events\",\"url\":\"/events\"},{\"_key\":\"7508d0e85be1\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"news\"},\"text\":\"News\"},{\"_key\":\"c1fb1a977ea5\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Startups program\",\"url\":\"https://www.anthropic.com/startups\"}],\"title\":\"Explore\"},{\"_key\":\"0cd9ca32ddc4\",\"links\":[{\"_key\":\"24af9e9bd295\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"_key\":\"367db330b179\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Availability\",\"url\":\"/supported-countries\"},{\"_key\":\"c04cac7ae925\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Support center\",\"url\":\"https://support.anthropic.com\"}],\"title\":\"Help and security\"},{\"_key\":\"43371d9865cf\",\"links\":[{\"_key\":\"09f32ce2569b\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Privacy choices\",\"url\":\"#\"},{\"_key\":\"8fd2735bc078\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Privacy policy\",\"url\":\"/legal/privacy\"},{\"_key\":\"151f2d4d7431\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":{\"_type\":\"page\",\"slug\":\"responsible-disclosure-policy\"},\"text\":\"Responsible disclosure policy\"},{\"_key\":\"51fecf5e2bc6\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Terms of service - consumer\",\"url\":\"/legal/consumer-terms\"},{\"_key\":\"4ffd7acc054e\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Terms of service - commercial\",\"url\":\"/legal/commercial-terms\"},{\"_key\":\"b5821a03666a\",\"_type\":\"link\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Usage policy\",\"url\":\"/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerLinks\":[{\"_key\":\"f3c804963853\",\"card\":{\"backgroundColor\":\"clay\",\"category\":\"News\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/b51062b617d3533149f3ff6fb2fb4a7be06b40db-202x202.svg\",\"width\":202},\"title\":\"Claude's Character\",\"url\":\"https://www.anthropic.com/news/claude-character\"},\"category\":\"Claude\",\"ctas\":[{\"_key\":\"bbe05ac2ec2d\",\"_type\":\"link\",\"text\":\"Download apps\",\"url\":\"https://claude.ai/download\"},{\"_key\":\"e694e1f56596\",\"_type\":\"link\",\"text\":\"Claude log in\",\"url\":\"https://claude.ai\"}],\"sections\":[{\"_key\":\"9be872e8c088\",\"ctas\":null,\"links\":[{\"_key\":\"7b9e2e1a920e\",\"_type\":\"link\",\"page\":null,\"text\":\"Overview\",\"url\":\"/claude\"},{\"_key\":\"c50614051409fd4e967a52a2fb01ed54\",\"_type\":\"link\",\"page\":null,\"text\":\"Max plan\",\"url\":\"/max\"},{\"_key\":\"87d96a948c27\",\"_type\":\"link\",\"page\":null,\"text\":\"Team plan\",\"url\":\"/team\"},{\"_key\":\"c7eb78d4a76c\",\"_type\":\"link\",\"page\":null,\"text\":\"Enterprise plan\",\"url\":\"/enterprise\"},{\"_key\":\"652005e6064e\",\"_type\":\"link\",\"page\":null,\"text\":\"Explore pricing\",\"url\":\"/pricing\"}],\"title\":\"Chat with Claude\"}]},{\"_key\":\"e08b40902cbb\",\"card\":{\"backgroundColor\":\"sky\",\"category\":\"Get started\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/3ba56e79baf0f554c4eefd9e7b2b03388b4c71f2-202x202.svg\",\"width\":202},\"title\":\"Learn how to build with Claude\",\"url\":\"https://docs.anthropic.com/en/docs/welcome\"},\"category\":\"API\",\"ctas\":[{\"_key\":\"951245c80d71\",\"_type\":\"link\",\"text\":\"Console log in\",\"url\":\"https://console.anthropic.com\"}],\"sections\":[{\"_key\":\"f5435c9757d4\",\"ctas\":null,\"links\":[{\"_key\":\"1d805e0b2516\",\"_type\":\"link\",\"page\":null,\"text\":\"API overview\",\"url\":\"/api\"},{\"_key\":\"48bd8d8dc982\",\"_type\":\"link\",\"page\":null,\"text\":\"Developer docs\",\"url\":\"https://docs.anthropic.com\"},{\"_key\":\"9667b32966f8\",\"_type\":\"link\",\"page\":null,\"text\":\"Explore pricing\",\"url\":\"/pricing#api\"}],\"title\":\"Build with Claude\"}]},{\"_key\":\"5ee6c9e8bb40\",\"card\":{\"backgroundColor\":\"heather\",\"category\":\"Case studies\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/979f7ac1f86e96870f547a788de6edce2e79f8ce-202x202.svg\",\"width\":202},\"title\":\"Hear from our customers\",\"url\":\"/customers\"},\"category\":\"Solutions\",\"sections\":[{\"_key\":\"86c91f34e78e\",\"ctas\":null,\"links\":[{\"_key\":\"ef97aea86c51\",\"_type\":\"link\",\"page\":null,\"text\":\"AI agents\",\"url\":\"/solutions/agents\"},{\"_key\":\"4601f5837a58\",\"_type\":\"link\",\"page\":null,\"text\":\"Coding\",\"url\":\"/solutions/coding\"},{\"_key\":\"9d8be85830aa\",\"_type\":\"link\",\"page\":null,\"text\":\"Customer support\",\"url\":\"/solutions/customer-support\"},{\"_key\":\"452aad7468f3\",\"_type\":\"link\",\"page\":null,\"text\":\"Education\",\"url\":\"/solutions/education\"},{\"_key\":\"987465dada46\",\"_type\":\"link\",\"page\":null,\"text\":\"Financial services\",\"url\":\"https://www.anthropic.com/solutions/financial-services\"}],\"title\":\"Collaborate with Claude\"}]},{\"_key\":\"be5d4ecfc005\",\"card\":{\"backgroundColor\":\"olive\",\"category\":\"Research\",\"illustration\":{\"description\":null,\"height\":205,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/057a57864dc1d2f7e6639a02f65ea77f08a19095-206x205.svg\",\"width\":206},\"title\":\"Claude’s extended thinking\",\"url\":\"https://www.anthropic.com/news/visible-extended-thinking\"},\"category\":\"Research\",\"sections\":[{\"_key\":\"cad375af37cc\",\"ctas\":null,\"links\":[{\"_key\":\"8782be9dc2e6\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-03-09T15:23:03Z\",\"_id\":\"b5e6b6d0-f668-4312-8a00-0e804343be62\",\"_rev\":\"8Ka5T868moynofPrGLUbQN\",\"_type\":\"page\",\"_updatedAt\":\"2024-06-20T14:51:58Z\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"19e3de5eb45a\",\"_ref\":\"fe5e453b-ae1a-431c-bea8-e54463427acf\",\"_type\":\"reference\"},{\"_key\":\"3eae5ef11e92\",\"_ref\":\"a50d379e-8adc-4ed2-9e76-d7235165cb25\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"research\"},\"title\":\"Research\"},\"text\":\"Overview\"},{\"_key\":\"2c08fec00aed\",\"_type\":\"link\",\"page\":null,\"text\":\"Economic Index\",\"url\":\"/economic-index\"}],\"title\":\"Research\"},{\"_key\":\"6efa8c7f7494\",\"ctas\":null,\"links\":[{\"_key\":\"818055e9fe1f\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2025-04-21T17:05:10Z\",\"_id\":\"b8764a5f-abd4-4309-99c5-e01e3ff51522\",\"_rev\":\"v1N2wBpLqoO2Q3HXueXvWh\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:05Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-fddc15df8b1165f09cd04d1f058ebf2fefdce044-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"c331074239a6\",\"_ref\":\"a34e7f7e-46f2-484f-b062-32731331e9b8\",\"_type\":\"reference\"},{\"_key\":\"9faf70e8babd\",\"_ref\":\"9c03dad9-7467-4b6e-8023-7d26aaa74ba5\",\"_type\":\"reference\"},{\"_key\":\"f8b0f6cdff5f\",\"_ref\":\"e2ca4bc4-7deb-4c63-90ce-6133e0e79485\",\"_type\":\"reference\"},{\"_key\":\"d4095061a27a\",\"_ref\":\"5a00b439-1474-430a-89ec-770fcbaba807\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/opus\"},\"title\":\"Claude Opus 4\"},\"text\":\"Claude Opus 4\"},{\"_key\":\"694bd6fd50da\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-09-25T13:40:13Z\",\"_id\":\"708a028d-58f2-4980-9a7c-a99523d8131f\",\"_rev\":\"6i7QQZ2OJnE58VEiPrJJZm\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:06Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-671633efbf2333613d6c37b73cb55e82cf52a531-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"efbca8873737\",\"_ref\":\"28727556-38a3-4a03-acbd-008f6d089de7\",\"_type\":\"reference\"},{\"_key\":\"23581c5e08d5\",\"_ref\":\"57b4e21b-6c38-4acc-8f1a-9e8ea518f76f\",\"_type\":\"reference\"},{\"_key\":\"f80cd327fa56\",\"_ref\":\"eb888530-a73b-4edc-9a84-dd16cadb8ee3\",\"_type\":\"reference\"},{\"_key\":\"6dd0528e1a73\",\"_ref\":\"5fe75448-6894-4e2c-ac2a-f5a24095b63a\",\"_type\":\"reference\"},{\"_key\":\"910bd8f316b6\",\"_ref\":\"e32cfcea-219c-42f4-8b1c-1ed0122ff768\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/sonnet\"},\"title\":\"Claude Sonnet 4\"},\"text\":\"Claude Sonnet 4\"},{\"_key\":\"0f9e98ccca5d\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-10-09T10:02:31Z\",\"_id\":\"1e71d541-7a84-444f-85e5-c316b148356e\",\"_rev\":\"3YEDAdif46o4m1ICOQXYPz\",\"_type\":\"page\",\"_updatedAt\":\"2025-05-23T14:04:03Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"meta\":{\"robotsIndexable\":true,\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-597723b70ccbe694ff3788144b3be87b9ce1536c-2400x1260-jpg\",\"_type\":\"reference\"}}},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"efbca8873737\",\"_ref\":\"46bd14aa-e4b3-435f-b3d8-2e4e63b32fda\",\"_type\":\"reference\"},{\"_key\":\"dfe0dacb58af\",\"_ref\":\"ae5d1645-49b9-422a-860f-2ba6e89afb8e\",\"_type\":\"reference\"},{\"_key\":\"5d9ed9fb4557\",\"_ref\":\"8f48e72e-488b-45a5-acf3-395ec7d644db\",\"_type\":\"reference\"},{\"_key\":\"57f111c726cf\",\"_ref\":\"6b9e22f8-135d-4e21-95c9-9bca6646fadf\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"claude/haiku\"},\"title\":\"Claude Haiku 3.5\"},\"text\":\"Claude Haiku 3.5\"}],\"title\":\"Claude model family\"}]},{\"_key\":\"b01af56fae81\",\"card\":{\"backgroundColor\":\"fig\",\"category\":\"Announcements\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/9caa14b490b0f02f7b3e5a37e6ea171f182a2544-202x202.svg\",\"width\":202},\"title\":\"ISO 42001 certification\",\"url\":\"/news/anthropic-achieves-iso-42001-certification-for-responsible-ai\"},\"category\":\"Commitments\",\"sections\":[{\"_key\":\"ae13eec166b3\",\"ctas\":null,\"links\":[{\"_key\":\"f1bf2286ea51\",\"_type\":\"link\",\"page\":null,\"text\":\"Transparency\",\"url\":\"/transparency\"},{\"_key\":\"0da6e18eb7d0\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-10-14T14:08:37Z\",\"_id\":\"19367d7a-f3f5-4316-b356-fd9fc6fcce46\",\"_rev\":\"7NkZcZZTh11FSYYzVK1kZK\",\"_type\":\"post\",\"_updatedAt\":\"2024-10-15T20:44:11Z\",\"body\":[{\"_key\":\"177824ba8e58\",\"_type\":\"block\",\"children\":[{\"_key\":\"b66b73206ce30\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. \"},{\"_key\":\"b66b73206ce31\",\"_type\":\"span\",\"marks\":[],\"text\":\"This update introduces a more flexible and nuanced approach to assessing and managing AI risks while maintaining our commitment not to train or deploy models unless we have implemented adequate safeguards. Key improvements include new capability thresholds to indicate when we will upgrade our safeguards, refined processes for evaluating model capabilities and the adequacy of our safeguards (inspired by \"},{\"_key\":\"b66b73206ce32\",\"_type\":\"span\",\"marks\":[\"a8d027e86aae\"],\"text\":\"safety case methodologies\"},{\"_key\":\"b66b73206ce33\",\"_type\":\"span\",\"marks\":[],\"text\":\"), and new measures for internal governance and external input. By learning from our implementation experiences and drawing on risk management practices used in other high-consequence industries, we aim to better prepare for the rapid pace of AI advancement.\"}],\"markDefs\":[{\"_key\":\"a8d027e86aae\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2403.10462\"}],\"style\":\"normal\"},{\"_key\":\"1c3077afa1f5\",\"_type\":\"block\",\"children\":[{\"_key\":\"9405114da2700\",\"_type\":\"span\",\"marks\":[],\"text\":\"The promise and challenge of advanced AI\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"750223c4acfb\",\"_type\":\"block\",\"children\":[{\"_key\":\"a1dcb0091c340\",\"_type\":\"span\",\"marks\":[],\"text\":\"As frontier AI models advance, they have the potential to bring about transformative benefits for our society and economy. AI could accelerate scientific discoveries, revolutionize healthcare, enhance our education system, and create entirely new domains for human creativity and innovation. However, frontier AI systems also present new challenges and risks that warrant careful study and effective safeguards.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c8b393e2960c\",\"_type\":\"block\",\"children\":[{\"_key\":\"b75aa93fa2c80\",\"_type\":\"span\",\"marks\":[],\"text\":\"In September 2023, we \"},{\"_key\":\"b75aa93fa2c81\",\"_type\":\"span\",\"marks\":[\"4791430b5ec2\"],\"text\":\"released\"},{\"_key\":\"b75aa93fa2c82\",\"_type\":\"span\",\"marks\":[],\"text\":\" our Responsible Scaling Policy, a framework for managing risks from increasingly capable AI systems. After a year of implementation and learning, we are now sharing a significantly updated version that reflects practical insights and accounts for advancing technological capabilities.\"}],\"markDefs\":[{\"_key\":\"4791430b5ec2\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/news/anthropics-responsible-scaling-policy\"}],\"style\":\"normal\"},{\"_key\":\"a1948e4cc873\",\"_type\":\"block\",\"children\":[{\"_key\":\"5d488fbe87cd0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Although this policy focuses on catastrophic risks like the categories listed below, they are not the only risks that we monitor and prepare for. Our \"},{\"_key\":\"5d488fbe87cd1\",\"_type\":\"span\",\"marks\":[\"ba04e1121891\"],\"text\":\"Usage Policy\"},{\"_key\":\"5d488fbe87cd2\",\"_type\":\"span\",\"marks\":[],\"text\":\" sets forth our standards for the use of our products, including rules that prohibit using our models to spread misinformation, incite violence or hateful behavior, or engage in fraudulent or abusive practices. We continually refine our technical measures for enforcing our trust and safety standards at scale. Further, we conduct research to understand the broader \"},{\"_key\":\"5d488fbe87cd3\",\"_type\":\"span\",\"marks\":[\"32798753cd99\"],\"text\":\"societal impacts\"},{\"_key\":\"5d488fbe87cd4\",\"_type\":\"span\",\"marks\":[],\"text\":\" of our models. Our Responsible Scaling Policy complements our work in these areas, contributing to our understanding of current and potential risks.\"}],\"markDefs\":[{\"_key\":\"ba04e1121891\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/legal/aup\"},{\"_key\":\"32798753cd99\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/research#societal-impacts\"}],\"style\":\"normal\"},{\"_key\":\"3b55c0bceff9\",\"_type\":\"block\",\"children\":[{\"_key\":\"5525570b2a010\",\"_type\":\"span\",\"marks\":[],\"text\":\"A framework for proportional safeguards\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"ad1d58dbdd5b\",\"_type\":\"block\",\"children\":[{\"_key\":\"cdd8f6a2997b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"As before, we maintain our core commitment: we will not train or deploy models unless we have implemented safety and security measures that keep risks below acceptable levels. Our RSP is based on the principle of proportional protection: safeguards that scale with potential risks. To do this, we use \"},{\"_key\":\"3517fb380020\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"AI Safety Level Standards (ASL Standards)\"},{\"_key\":\"aede15153eee\",\"_type\":\"span\",\"marks\":[],\"text\":\", graduated sets of safety and security measures that become more stringent as model capabilities increase. Inspired by \"},{\"_key\":\"cdd8f6a2997b1\",\"_type\":\"span\",\"marks\":[\"f8e6f3368061\"],\"text\":\"Biosafety Levels,\"},{\"_key\":\"cdd8f6a2997b2\",\"_type\":\"span\",\"marks\":[],\"text\":\" these begin at ASL-1 for models that have very basic capabilities (for example, chess-playing bots) and progress through ASL-2, ASL-3, and so on.\"}],\"markDefs\":[{\"_key\":\"f8e6f3368061\",\"_type\":\"link\",\"href\":\"https://en.wikipedia.org/wiki/Biosafety_level\"}],\"style\":\"normal\"},{\"_key\":\"18e2a21a8d24\",\"_type\":\"block\",\"children\":[{\"_key\":\"94961b6308040\",\"_type\":\"span\",\"marks\":[],\"text\":\"In our updated policy, we have refined our methodology for assessing specific capabilities (and their associated risks) and implementing proportional safety and security measures. Our updated framework has two key components:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"110d48e0214c\",\"_type\":\"block\",\"children\":[{\"_key\":\"4fa1b51cfc900\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Capability Thresholds:\"},{\"_key\":\"f90398ece8b9\",\"_type\":\"span\",\"marks\":[],\"text\":\" Specific AI abilities that, if reached, would require stronger safeguards than our current baseline.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"132d0001c926\",\"_type\":\"block\",\"children\":[{\"_key\":\"d0053cd57ea60\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Required Safeguards: \"},{\"_key\":\"663a30c5e5b1\",\"_type\":\"span\",\"marks\":[],\"text\":\"The specific ASL Standards needed to mitigate risks once a Capability Threshold has been reached.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"36479c291519\",\"_type\":\"block\",\"children\":[{\"_key\":\"a03bfcd2c90a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"At present, all of our models operate under ASL-2 Standards, which reflect current industry best practices. Our updated policy defines two key Capability Thresholds that would require upgraded safeguards:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"7960a2e610b8\",\"_type\":\"block\",\"children\":[{\"_key\":\"113a03232f950\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Autonomous AI Research and Development:\"},{\"_key\":\"559bae44e291\",\"_type\":\"span\",\"marks\":[],\"text\":\" If a model can independently conduct complex AI research tasks typically requiring human expertise—potentially significantly accelerating AI development in an unpredictable way—we require elevated security standards (potentially ASL-4 or higher standards) and additional safety assurances to avoid a situation where development outpaces our ability to address emerging risks.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b1e7e0200f28\",\"_type\":\"block\",\"children\":[{\"_key\":\"04f8008234340\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Chemical, Biological, Radiological, and Nuclear (CBRN) weapons:\"},{\"_key\":\"e87c145d832e\",\"_type\":\"span\",\"marks\":[],\"text\":\" If a model can meaningfully assist someone with a basic technical background in creating or deploying CBRN weapons, we require enhanced security and deployment safeguards (ASL-3 standards).\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5028d8139378\",\"_type\":\"block\",\"children\":[{\"_key\":\"c21521b5c8660\",\"_type\":\"span\",\"marks\":[],\"text\":\"ASL-3 safeguards involve enhanced security measures and deployment controls. On the security side, this will include internal access controls and more robust protection of model weights. For deployment risks, we plan to implement a multi-layered approach to prevent misuse, including real-time and asynchronous monitoring, rapid response protocols, and thorough pre-deployment red teaming.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9d149ea1669f\",\"_type\":\"block\",\"children\":[{\"_key\":\"c9476c97d6320\",\"_type\":\"span\",\"marks\":[],\"text\":\"Implementation and oversight\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"081edde580ae\",\"_type\":\"block\",\"children\":[{\"_key\":\"0898891e3fd00\",\"_type\":\"span\",\"marks\":[],\"text\":\"To contribute to effective implementation of the policy, we have established:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1ef822ef2fa2\",\"_type\":\"block\",\"children\":[{\"_key\":\"65ad635ebc020\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Capability assessments\"},{\"_key\":\"ee8bb23f5481\",\"_type\":\"span\",\"marks\":[],\"text\":\": Routine model evaluations based on our Capability Thresholds to determine whether our current safeguards are still appropriate. (Summaries of past assessments are available \"},{\"_key\":\"65ad635ebc021\",\"_type\":\"span\",\"marks\":[\"e97965203d94\"],\"text\":\"here\"},{\"_key\":\"65ad635ebc022\",\"_type\":\"span\",\"marks\":[],\"text\":\".)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"e97965203d94\",\"_type\":\"link\",\"href\":\"http://www.anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"b5fc19b935bb\",\"_type\":\"block\",\"children\":[{\"_key\":\"fd96692cf5950\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Safeguard assessments: \"},{\"_key\":\"bbdf4a0ded13\",\"_type\":\"span\",\"marks\":[],\"text\":\"Routine evaluation of the effectiveness of our security and deployment safety measures to assess whether we have met the Required Safeguards bar. (Summaries of these decisions will be available \"},{\"_key\":\"fd96692cf5951\",\"_type\":\"span\",\"marks\":[\"d6b74c71ad6d\"],\"text\":\"here\"},{\"_key\":\"fd96692cf5952\",\"_type\":\"span\",\"marks\":[],\"text\":\".)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"d6b74c71ad6d\",\"_type\":\"link\",\"href\":\"http://www.anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"8074ca752c13\",\"_type\":\"block\",\"children\":[{\"_key\":\"ed8d6ec6368a0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Documentation and decision-making: \"},{\"_key\":\"d451a32ef6cb\",\"_type\":\"span\",\"marks\":[],\"text\":\"Processes for documenting the capability and safeguard assessments, inspired by procedures (such as \"},{\"_key\":\"ed8d6ec6368a1\",\"_type\":\"span\",\"marks\":[\"dd97b493d101\"],\"text\":\"safety case methodologies\"},{\"_key\":\"ed8d6ec6368a2\",\"_type\":\"span\",\"marks\":[],\"text\":\") common in high-reliability industries.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[{\"_key\":\"dd97b493d101\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2403.10462\"}],\"style\":\"normal\"},{\"_key\":\"60c9b7dabd40\",\"_type\":\"block\",\"children\":[{\"_key\":\"ca95d473f4a90\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Measures for internal governance and external input: \"},{\"_key\":\"fb68635efd29\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our assessment methodology will be backed up by internal stress-testing in addition to our existing internal reporting process for safety issues. We are also soliciting external expert feedback on our methodologies.\"},{\"_key\":\"7ddd60e07d17\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"1\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6e5effe0bac6\",\"_type\":\"block\",\"children\":[{\"_key\":\"ecdac5e44ed40\",\"_type\":\"span\",\"marks\":[],\"text\":\"Learning from experience\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"142037ff4afb\",\"_type\":\"block\",\"children\":[{\"_key\":\"8932eeee77830\",\"_type\":\"span\",\"marks\":[],\"text\":\"We have learned a lot in our first year with the previous RSP in effect, and are using this update as an opportunity to reflect on what has worked well and what makes sense to update in the policy. As part of this, we conducted our first review of how well we adhered to the framework and identified a small number of instances where we fell short of meeting the full letter of its requirements. These included procedural issues such as completing a set of evaluations three days later than scheduled or a lack of clarity on how and where we should note any changes to our placeholder evaluations. We also flagged some evaluations where we may have been able to elicit slightly better model performance through implementing standard techniques (such as chain-of-thought or best-of-N).\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fdd39c742e14\",\"_type\":\"block\",\"children\":[{\"_key\":\"2c9de8a77cf10\",\"_type\":\"span\",\"marks\":[],\"text\":\"In all cases, we found these instances posed minimal risk to the safety of our models. We used the additional three days to refine and improve our evaluations; the different set of evaluations we used provided a more accurate assessment than the placeholder evaluations; and our evaluation methodology still showed we were sufficiently far from the thresholds. From this, we learned two valuable lessons to incorporate into our updated framework: we needed to incorporate more flexibility into our policies, and we needed to improve our process for tracking compliance with the RSP. You can read more \"},{\"_key\":\"2c9de8a77cf11\",\"_type\":\"span\",\"marks\":[\"724c1bcc37c6\"],\"text\":\"here\"},{\"_key\":\"2c9de8a77cf12\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"724c1bcc37c6\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"c84e70ee115b\",\"_type\":\"block\",\"children\":[{\"_key\":\"855d60a456920\",\"_type\":\"span\",\"marks\":[],\"text\":\"Since we first released the RSP a year ago, our goal has been to offer an example of a framework that others might draw inspiration from when crafting their own AI risk governance policies. We hope that proactively sharing our experiences implementing our own policy will help other companies in implementing their own risk management frameworks and contribute to the establishment of best practices across the AI ecosystem.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"20a9139b3a51\",\"_type\":\"block\",\"children\":[{\"_key\":\"81a081f760a10\",\"_type\":\"span\",\"marks\":[],\"text\":\"Looking ahead\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"78baf5750bd0\",\"_type\":\"block\",\"children\":[{\"_key\":\"252e5f0060c50\",\"_type\":\"span\",\"marks\":[],\"text\":\"The frontier of AI is advancing rapidly, making it challenging to anticipate what safety measures will be appropriate for future systems. All aspects of our safety program will continue to evolve: our policies, evaluation methodology, safeguards, and our research into potential risks and mitigations.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2afadf824368\",\"_type\":\"block\",\"children\":[{\"_key\":\"744b6d45ddff0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Additionally, Co-Founder and Chief Science Officer Jared Kaplan will serve as Anthropic’s Responsible Scaling Officer, succeeding Co-Founder and Chief Technology Officer Sam McCandlish who held this role over the last year. Sam oversaw the RSP’s initial implementation and will continue to focus on his duties as Chief Technology Officer. As we work to scale up our efforts on implementing the RSP, we’re also opening a position for a Head of Responsible Scaling. This role will be responsible for coordinating the many teams needed to iterate on and successfully comply with the RSP.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"88e4ecab085f\",\"_type\":\"block\",\"children\":[{\"_key\":\"d603f352b2580\",\"_type\":\"span\",\"marks\":[],\"text\":\"If you would like to contribute to AI risk management at Anthropic, \"},{\"_key\":\"d0297560aab0\",\"_type\":\"span\",\"marks\":[\"6210958b799c\"],\"text\":\"we are hiring\"},{\"_key\":\"ec2a1674bc0a\",\"_type\":\"span\",\"marks\":[],\"text\":\"! Many of our teams now contribute to risk management via the RSP, including:\"}],\"markDefs\":[{\"_key\":\"6210958b799c\",\"_type\":\"link\",\"href\":\"https://www.anthropic.com/jobs\"}],\"style\":\"normal\"},{\"_key\":\"803749c5db22\",\"_type\":\"block\",\"children\":[{\"_key\":\"0a4d9f27a0cd0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Frontier Red Team (responsible for threat modeling and capability assessments)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fe760029da3a\",\"_type\":\"block\",\"children\":[{\"_key\":\"dc5557c893ca0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Trust \u0026 Safety (responsible for developing deployment safeguards)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"97772c2e43a6\",\"_type\":\"block\",\"children\":[{\"_key\":\"b2222f32b3830\",\"_type\":\"span\",\"marks\":[],\"text\":\"Security and Compliance (responsible for security safeguards and risk management)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"bed9fc27e95a\",\"_type\":\"block\",\"children\":[{\"_key\":\"32cf53008a870\",\"_type\":\"span\",\"marks\":[],\"text\":\"Alignment Science (including sub-teams responsible for developing ASL-3+ safety measures, for misalignment-focused capability evaluations, and for our internal alignment stress-testing program)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ddb2b97916b4\",\"_type\":\"block\",\"children\":[{\"_key\":\"5dd36bc76b200\",\"_type\":\"span\",\"marks\":[],\"text\":\"RSP Team (responsible for policy drafting, assurance, and cross-company execution)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"82e7288c8b9b\",\"_type\":\"block\",\"children\":[{\"_key\":\"ff739d8fa1fb0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Read the updated policy at \"},{\"_key\":\"ff739d8fa1fb1\",\"_type\":\"span\",\"marks\":[\"64573f7728d5\",\"strong\"],\"text\":\"anthropic.com/rsp\"},{\"_key\":\"ff739d8fa1fb2\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\", and supplementary information at \"},{\"_key\":\"ff739d8fa1fb3\",\"_type\":\"span\",\"marks\":[\"0b409c03c219\",\"strong\"],\"text\":\"anthropic.com/rsp-updates\"},{\"_key\":\"f2c90e528143\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"64573f7728d5\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp\"},{\"_key\":\"0b409c03c219\",\"_type\":\"link\",\"href\":\"http://anthropic.com/rsp-updates\"}],\"style\":\"normal\"},{\"_key\":\"4730ec071c8d\",\"_type\":\"block\",\"children\":[{\"_key\":\"f524c11dc591\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"We extend our sincere gratitude to the many external groups that provided invaluable feedback on the development and refinement of our Responsible Scaling Policy.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"df20b8535b76\",\"_type\":\"block\",\"children\":[{\"_key\":\"3c4f171f7b070\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\n\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5995bb58cadf\",\"_type\":\"block\",\"children\":[{\"_key\":\"8bcb9103a3e80\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6d34bef42728\",\"_type\":\"block\",\"children\":[{\"_key\":\"3a62da5cab740\",\"_type\":\"span\",\"marks\":[],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"}],\"cardPhoto\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-591404bad10f6fb79c2561d72999e30d633792f2-1312x1312-png\",\"_type\":\"reference\"},\"description\":\"A hand with a feather quill writing a policy document. \"},\"cta\":{\"_type\":\"link\",\"text\":\"Read the Responsible Scaling Policy \",\"url\":\"http://anthropic.com/rsp \"},\"directories\":[{\"_key\":\"news\",\"_type\":\"tag\",\"label\":\"News\",\"value\":\"news\"}],\"fileAsset\":null,\"footnotesBody\":[{\"_key\":\"0de7792a2f97\",\"_type\":\"block\",\"children\":[{\"_key\":\"becd184f796c\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"1\"},{\"_key\":\"1aba967f3e65\",\"_type\":\"span\",\"marks\":[],\"text\":\" \"},{\"_key\":\"4061449d7e34\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"We have also shared our assessment methodology with both AI Safety Institutes, as well as a selection of independent experts and organizations, for feedback. This does not represent an endorsement from either AI Safety Institute or the independent experts and organizations. \"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e012dfcd0680\",\"_type\":\"block\",\"children\":[{\"_key\":\"a5a0fc3d405c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\n\"}],\"markDefs\":[],\"style\":\"normal\"}],\"footnotesTitle\":\"Footnotes\",\"hero\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-f1664b95be4e2e828a180cf9f015a0b6f8365472-5760x3240-png\",\"_type\":\"reference\"},\"description\":\"A hand with a feather quill writing a policy document. \"},\"hideCardPhotos\":true,\"meta\":{\"robotsIndexable\":true,\"seoDescription\":\"Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. \",\"seoTitle\":\"Announcing our updated Responsible Scaling Policy\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-4048dcbe1e4e38c32891bfb7ca28c1b7628982cd-2400x1260-png\",\"_type\":\"reference\"},\"description\":\"A hand writing on a policy document with a feathered quill.\"}},\"modalId\":null,\"page\":null,\"publishedOn\":\"2024-10-15T13:30:00.000Z\",\"relatedLinksLabel\":\"Related\",\"slug\":{\"_type\":\"slug\",\"current\":\"announcing-our-updated-responsible-scaling-policy\"},\"subjects\":[{\"_key\":\"announcements\",\"_type\":\"tag\",\"label\":\"Announcements\",\"value\":\"announcements\"}],\"title\":\"Announcing our updated Responsible Scaling Policy\"},\"text\":\"Responsible scaling policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"560566d26fd7\",\"ctas\":null,\"links\":[{\"_key\":\"dbaa54335108\",\"_type\":\"link\",\"page\":null,\"text\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com\"}],\"title\":\"Trust center\"}]},{\"_key\":\"cd1c8470153f\",\"card\":{\"backgroundColor\":\"cactus\",\"category\":\"Engineering\",\"illustration\":{\"description\":null,\"height\":202,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/ba1df32e7763906f03faafe0296daa48582e33f1-202x202.svg\",\"width\":202},\"title\":\"Building effective agents\",\"url\":\"/engineering/building-effective-agents\"},\"category\":\"Learn\",\"sections\":[{\"_key\":\"7a719b73abbb\",\"ctas\":null,\"links\":[{\"_key\":\"007e6aabc528\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-01-30T00:11:55Z\",\"_id\":\"e2db4c62-abf9-4a1c-9a98-5ff2b79f2320\",\"_rev\":\"uw6aKX3p7ldDBUNqIn6RAI\",\"_system\":{\"base\":{\"id\":\"e2db4c62-abf9-4a1c-9a98-5ff2b79f2320\",\"rev\":\"e1SehYHuBOmzIsNebUGsLA\"}},\"_type\":\"page\",\"_updatedAt\":\"2025-06-24T21:09:08Z\",\"backgroundColor\":\"ivory-light\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"88aa1cc7438d\",\"_ref\":\"9ceeaa12-216b-451f-936d-148ae89bd9a4\",\"_type\":\"reference\"},{\"_key\":\"fd2e4c8f9cf9\",\"_ref\":\"9acb1a29-a11f-4bf3-9b48-34e84f719f4c\",\"_type\":\"reference\"}],\"showParentBreadcrumb\":false,\"slug\":{\"_type\":\"slug\",\"current\":\"customers\"},\"title\":\"Customers\"},\"text\":\"Customer stories\"},{\"_key\":\"31bccebee35f\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2025-01-15T15:45:48Z\",\"_id\":\"8eaf3767-6721-42f3-859e-a543f19d47ce\",\"_rev\":\"3R9N6zTx1UJr6GwDEwhCSk\",\"_type\":\"page\",\"_updatedAt\":\"2025-01-24T13:34:54Z\",\"backgroundColor\":\"default\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"meta\":{\"robotsIndexable\":true},\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"3d5239c1764e\",\"_ref\":\"e17da550-f3b8-4db6-9468-450735111295\",\"_type\":\"reference\"},{\"_key\":\"db37cd406356\",\"_ref\":\"2e2c486e-e54f-4f6f-afa9-a2ccbb2ff50e\",\"_type\":\"reference\"},{\"_key\":\"80c405b7b714\",\"_ref\":\"2c96ba24-d412-474a-8a42-32313c274e68\",\"_type\":\"reference\"}],\"slug\":{\"_type\":\"slug\",\"current\":\"engineering\"},\"title\":\"Engineering\"},\"text\":\"Engineering at Anthropic\"},{\"_key\":\"e84dc24f1ec9\",\"_type\":\"link\",\"page\":null,\"text\":\"Anthropic Academy\",\"url\":\"/learn\"}],\"title\":\"Learning resources\"},{\"_key\":\"c2bbb3e1ab9e\",\"ctas\":null,\"links\":[{\"_key\":\"1752279b09b4\",\"_type\":\"link\",\"page\":null,\"text\":\"About\",\"url\":\"/company\"},{\"_key\":\"64be129555a4\",\"_type\":\"link\",\"page\":null,\"text\":\"Careers\",\"url\":\"/careers\"},{\"_key\":\"16942f1cf8cd\",\"_type\":\"link\",\"page\":null,\"text\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"e5092f7e4cbe\",\"card\":{\"backgroundColor\":\"default\",\"illustration\":{\"description\":null,\"height\":218,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/9f1bfa202fd78bc4743325ee8199cf18522bb4e7-232x218.svg\",\"width\":232}},\"category\":\"News\",\"sections\":[{\"_key\":\"fc4a00e73c8e\",\"ctas\":null,\"links\":[{\"_key\":\"86995b085b67\",\"_type\":\"link\",\"page\":{\"_createdAt\":\"2024-06-01T05:13:58Z\",\"_id\":\"65ed983f-1db1-4655-b662-8c7169802ac8\",\"_rev\":\"7NkZcZZTh11FSYYzW6mvR0\",\"_type\":\"page\",\"_updatedAt\":\"2024-10-22T14:59:18Z\",\"backgroundColor\":\"ivory-medium\",\"fileAsset\":null,\"internalPageType\":\"anthropic\",\"modalId\":null,\"page\":null,\"sections\":[{\"_key\":\"9f02fd3a3264\",\"_ref\":\"d0b62aec-4f07-4c1d-a81b-e3886b962d69\",\"_type\":\"reference\"},{\"_key\":\"f0382a77591e\",\"_ref\":\"243ed60e-70f7-4392-a626-2138ef076c18\",\"_type\":\"reference\"}],\"showParentBreadcrumb\":false,\"slug\":{\"_type\":\"slug\",\"current\":\"news\"},\"title\":\"Newsroom\"},\"text\":\"News\"}],\"title\":\"Latest Updates\"}]}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"navCta\":{\"_createdAt\":\"2024-01-12T17:43:21Z\",\"_id\":\"25aac41e-7435-47df-b392-6ea22f2abf0b\",\"_rev\":\"1oQP6cQFlFaIeBWKVicLJ3\",\"_type\":\"link\",\"_updatedAt\":\"2024-06-25T14:41:03Z\",\"fileAsset\":null,\"modalId\":null,\"page\":null,\"text\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/amazon-bedrock\",\"/api\",\"/app-unavailable-in-region\",\"/campus\",\"/careers\",\"/claude\",\"/claude-code\",\"/claude-in-slack\",\"/claude-in-slack/error\",\"/claude-in-slack/installation-disabled\",\"/claude-in-slack/success\",\"/claude-in-slack/upgrade-success\",\"/company\",\"/contact-sales\",\"/enterprise\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/for/parents\",\"/for/students\",\"/for/writers\",\"/google-cloud-vertex-ai\",\"/max\",\"/partners/mcp\",\"/partners/powered-by-claude\",\"/pricing\",\"/solutions/agents\",\"/solutions/coding\",\"/solutions/customer-support\",\"/solutions/education\",\"/solutions/financial-services\",\"/supported-countries\",\"/team\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\",\"hideFooter\":true},\"page\":{\"_type\":\"page\",\"_id\":\"not-found\",\"_rev\":\"\",\"_createdAt\":\"\",\"_updatedAt\":\"\",\"title\":\"Not Found\",\"slug\":{\"_type\":\"slug\",\"current\":\"not-found\"},\"meta\":{},\"sections\":[]},\"children\":[\"$\",\"$L26\",null,{}]}]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"21:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"name\":\"theme-color\",\"content\":\"#141413\"}],[\"$\",\"meta\",\"2\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"3\",{\"children\":\"How we built our multi-agent research system \\\\ Anthropic\"}],[\"$\",\"meta\",\"4\",{\"name\":\"description\",\"content\":\"On the the engineering challenges and lessons learned from building Claude's Research system\"}],[\"$\",\"meta\",\"5\",{\"name\":\"msapplication-TileColor\",\"content\":\"141413\"}],[\"$\",\"meta\",\"6\",{\"name\":\"msapplication-config\",\"content\":\"/browserconfig.xml\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"How we built our multi-agent research system\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"On the the engineering challenges and lessons learned from building Claude's Research system\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"Anthropic logo\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:site\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:creator\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:title\",\"content\":\"How we built our multi-agent research system\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:description\",\"content\":\"On the the engineering challenges and lessons learned from building Claude's Research system\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/5cf046fff69b847bfa78c12723dd466b285c0218-2400x1260.png\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:image:alt\",\"content\":\"Anthropic logo\"}],[\"$\",\"link\",\"19\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/images/icons/favicon-32x32.png\"}],[\"$\",\"link\",\"21\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\"}],[\"$\",\"link\",\"22\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\",\"sizes\":\"180x180\"}],[\"$\",\"link\",\"23\",{\"rel\":\"mask-icon\",\"href\":\"/images/icons/safari-pinned-tab.svg\",\"color\":\"141413\"}],[\"$\",\"meta\",\"24\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script nonce="MzMyYjc2M2ItMzgzYS00ZTUxLWIxOGUtOGNhYmU3YWZhMjEx">self.__next_f.push([1,"18:null\n"])</script></body></html>